# üõ†Ô∏è MambaVision TF Kernel: Project Dev Context

Documento t√©cnico de esquema de componentes para enrutamiento r√°pido del proyecto. Si est√°s implementando nuevo c√≥digo, revisa estas invariables arquitect√≥nicas.

## 1. M√≥dulo 1: Pipeline de Construcci√≥n (`CMakeLists.txt`)
- **Sistema de dependencias:** Gestionado enteramente por CMake delegando subprocesos de Python para extraer las rutas e includes del framework interno de TF (`tf.sysconfig`).
- **Orquestador H√≠brido:**
  - C√≥digo `.cc` pasa por `g++` (modo C++17, obligatorio).
  - C√≥digo `.cu` pasa por `nvcc`.
- **Estrategia de Banderas de Compilaci√≥n (Opci√≥n Robusta):**
  - **Host:** `-fPIC` (Position Independent Code, para `.so` din√°mico) y `-O2` por estabilidad.
  - **Device/CUDA:** `-O3` (agresividad m√°xima iterativa) y `-lineinfo` para perfiles Nsight (`ncu`/`nsys`) sin sobrecarga temporal.
  - **Ensamblador Target:** Fijado a `CUDA_ARCHITECTURES "75;80"` (T4 y A100). Evita la generaci√≥n intermedia gen√©rica (PTX JIT) previniendo las demoras masivas de la primera pasada ("warmup stall").

## 2. M√≥dulo 2: Driver del Kernel C++ (`mamba_ssm_op.cc`)
- **Registro API (`REGISTER_OP`):** Define el bloque de interface a Python (`MambaSelectiveScan`). Implementa *shape inference*, la cual se espera que por lo general preserve la dimensionalidad de salida (`out_tensor_shape == in_tensor_shape`).
- **El Centinela (Clase `OpKernel`):**
  - Instanciada e inyectada expl√≠citamente a Device GPU (`REGISTER_KERNEL_BUILDER(Name("MambaSelectiveScan").Device(DEVICE_GPU))`), lo cual obliga a TensorFlow a alojar impl√≠citamente la memoria en VRAM, eliminando las copias `cudaMemcpyHostToDevice`.
  - **Procedimiento `Compute`:** Requisitos formales fuertes (`OP_REQUIRES` a dimensionalidad correcta), lectura de sub-dimensiones tensoras.
  - **Puente Punteros:** Extrae `input_tensor.flat<float>().data()` (Direcci√≥n C subyacente cruda de memoria gr√°fica).
- **Ejecuci√≥n As√≠ncrona:** Llama al encapsulador CUDA externo (definido via `extern "C"`) el cual orquestar√° los *Blocks* y *Threads*, retornando el status de CUDA para ser escalado como excepci√≥n estandarizada C++ a Python.

## 3. M√≥dulo 3: Ejecuci√≥n F√≠sica CUDA (`mamba_ssm_kernel.cu`)
*(Actual en Fase de Desarrollo)*
- Expone obligatoriamente un conector C compatible: `extern "C" int LaunchMambaSelectiveScan(...)`.
- Responsable de la asignaci√≥n l√≥gica de `dim3 blocks, threads`, transferencia controlada a `__shared__` memory para computaci√≥n acelerada, y bloqueos por barrera (`__syncthreads()`).

## 4. M√≥dulo 4: Pipeline CI/CD Ef√≠mero (`compilador.ipynb`)
El entorno de integraci√≥n as√≠ncrono se realiza mediante celdas en Colab.
1. Actualizaci√≥n sincronizada via GitHub API (`git pull`).
2. Delega expl√≠citamente toda macro compilaci√≥n al binario local haciendo un hard reset `/build` -> `cmake ..` -> `make -j`.
3. **Parche Cr√≠tico de Binding (Linker Resolver):** Dado el ecosistema precompilado *out-of-tree* en Colab, es imperativo interconectar din√°micamente los s√≠mbolos no resueltos (`undefined symbol: _ZTVN10...`) inyectando v√≠a alto nivel:
   ```python
   import ctypes
   ctypes.CDLL('/usr/local/lib/python3.12/dist-packages/tensorflow/libtensorflow_framework.so.2', ctypes.RTLD_GLOBAL)
   ```
   Antes de llamar a `tf.load_op_library("build/libmamba_kernel.so")`.
4. Pruebas iterativas: Inyecci√≥n expl√≠cita de tensores de validaci√≥n bajo scope forzado `with tf.device('/GPU:0'):` y comprobaci√≥n asercional matem√°tica `np.allclose`.
