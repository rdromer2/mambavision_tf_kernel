# **Análisis Estructural y Protocolo de Migración Transdimensional de MambaVision: De PyTorch a Keras 3**

## **Fundamentos Teóricos y Evolución de la Arquitectura MambaVision**

El modelado secuencial y espacial en el aprendizaje profundo ha experimentado un cambio de paradigma fenomenal con la introducción de los Modelos de Espacio de Estados (SSMs, por sus siglas en inglés). Originalmente concebidos para procesar señales unidimensionales de tiempo continuo y posteriormente adaptados para el procesamiento de lenguaje natural a través de arquitecturas como S4 y el modelo Mamba original, los SSMs ofrecen una complejidad computacional lineal ![][image1] respecto a la longitud de la secuencia, superando la complejidad cuadrática ![][image2] que paraliza a los Transformers tradicionales en contextos de ventanas de contexto largas.1 La formulación matemática fundacional de estos modelos describe un sistema físico mediante variables de estado ocultas ![][image3], procesadas mediante una matriz de transición ![][image4] que obliga a la estabilidad mediante valores propios negativos, y matrices de proyección ![][image5] y ![][image6] que asimilan la entrada y emiten la salida, respectivamente.2 Sin embargo, la migración de este paradigma estrictamente secuencial y causal al dominio del procesamiento de imágenes, donde la dependencia espacial es bidireccional y bidimensional, presentó un desafío computacional significativo.

Presentado en la prestigiosa conferencia CVPR 2025 por investigadores de NVIDIA, MambaVision emerge como una solución arquitectónica híbrida de vanguardia que reescribe la aplicabilidad de los SSMs para la visión por computadora.5 A diferencia de iteraciones previas como Vision Mamba (Vim), que dependían de un procesamiento bidireccional exhaustivo que ralentizaba la inferencia y el entrenamiento debido a la sobrecarga computacional de procesar secuencias hacia adelante y hacia atrás de manera redundante 8, MambaVision propone un diseño jerárquico finamente calibrado. Esta arquitectura extrae características semánticas a través de cuatro etapas progresivas, fusionando la extracción de características de alta frecuencia mediante redes neuronales convolucionales (CNN) en las etapas tempranas, y delegando el razonamiento global a una amalgama de bloques Mamba modificados y bloques de autoatención (Transformers) en las etapas profundas.9

El impacto empírico de esta hibridación ha establecido una nueva frontera de Pareto en el conjunto de datos ImageNet-1K, logrando un equilibrio sin precedentes entre la exactitud (Top-1 accuracy) y el rendimiento de procesamiento de imágenes (throughput).10 Modelos a escala como MambaVision-L-21K demuestran esta superioridad al alcanzar una precisión del ![][image7] tras un preentrenamiento en ImageNet-21K y ajuste fino en ImageNet-1K, con ![][image8] millones de parámetros y ![][image9] GFLOPs a una resolución de ![][image10].6 Adicionalmente, el modelo supera a arquitecturas equivalentes en tareas de procesamiento en sentido descendente (downstream), como la detección de objetos y la segmentación semántica en los conjuntos de datos MS COCO y ADE20K, cimentando su estatus como un extractor de características de propósito general excepcionalmente robusto.10

La implementación oficial de este modelo reside nativamente en PyTorch, utilizando abstracciones de nivel inferior para invocar núcleos CUDA altamente optimizados para la operación de escaneo selectivo (selective\_scan\_fn).9 No obstante, los imperativos de despliegue industrial, la compilación de grafos computacionales para aceleradores tensores (TPUs) y la necesidad de agnosticismos de hardware requieren la transmutación de estos pesos hacia el ecosistema multi-backend de Keras 3\.15 Keras 3 permite ejecutar modelos sobre TensorFlow, JAX o PyTorch indistintamente, pero impone arquitecturas de tensores radicalmente diferentes. Este informe deconstruye el diccionario de estados (state\_dict) de PyTorch, mapea su ontología tensorial y formula un protocolo de migración matemáticamente riguroso hacia Keras 3\.

## **Disección Anatómica del state\_dict en PyTorch**

El mecanismo de serialización y preservación de estado en PyTorch consolida los tensores multidimensionales aprendibles (pesos, sesgos) y las estadísticas móviles continuas (medias y varianzas de normalización de lotes) en un diccionario ordenado de Python referenciado como state\_dict.16 En MambaVision, este diccionario encapsula una topología jerárquica densa. La invocación de torch.load revela que los puntos de control frecuentemente albergan metadatos externos y anomalías de nomenclatura dependientes del contexto de entrenamiento original. Por ejemplo, los regímenes de Entrenamiento Distribuido de Datos (DDP) a menudo anteponen el prefijo module. a todas las claves, mientras que ciertas abstracciones de extracción de características anteponen el prefijo encoder..17 El código base oficial incluye rutinas heurísticas para limpiar estos artefactos, despojando a las claves de los primeros siete caracteres si detectan la presencia paralela, o reemplazando subcadenas específicas.17

Una vez esterilizado de artefactos de entrenamiento transitorios, el diccionario expone una taxonomía de capas intrincada que mapea directamente la concepción teórica de la red. Para facilitar una comprensión exhaustiva de los prefijos reales y los tensores alojados, la arquitectura se divide analíticamente en cinco componentes cardinales: la incrustación de parches (Stem/PatchEmbed), las etapas de submuestreo espacial (Downsample), los bloques convolucionales de extracción temprana (ConvBlocks), los bloques de mezcla jerárquica (MambaVisionMixer y TransformerBlock), y el cabezal clasificador global (Head).

### **Módulo de Incrustación de Parches (PatchEmbed)**

El procesamiento inicial de cualquier tensor de imagen tridimensional de entrada ![][image11] requiere una proyección a un espacio de incrustación de alta dimensión y una subsiguiente o simultánea reducción de la resolución espacial. En MambaVision, este proceso no se delega a una única convolución agresiva (como ocurre en el proyector clásico de los Vision Transformers), sino a un submódulo secuencial compuesto denominado PatchEmbed, que ejecuta dos convoluciones superpuestas intercaladas con normalización y activaciones no lineales.17

La lógica subyacente de este enfoque dual es minimizar la pérdida abrupta de información estructural de alta frecuencia, un defecto bien documentado en las proyecciones de un solo paso. El bloque de código de PyTorch encapsula estas operaciones en una variable nn.Sequential llamada conv\_down.17 La proyección semántica abstracta proj, a menudo invocada para homogeneizar interfaces con arquitecturas preexistentes, se define matemáticamente como un mapeo de identidad (nn.Identity()), por lo que no genera vectores de estado.17 La estructura precisa extraída del state\_dict se ilustra en la tabla adjunta.

| Prefijo Exacto del state\_dict PyTorch | Instanciación de Clase Subyacente | Función Matemática y Dimensionalidad |
| :---- | :---- | :---- |
| patch\_embed.conv\_down.0.weight | nn.Conv2d (![][image12], stride 2, padding 1\) | Proyección inicial del espacio de color a la dimensión intermedia. Carece de tensor de sesgo (bias=False). |
| patch\_embed.conv\_down.1.weight | nn.BatchNorm2d (![][image13]) | Parámetro de escalado afín para la normalización espacial intermedia. |
| patch\_embed.conv\_down.1.bias | nn.BatchNorm2d (![][image14]) | Parámetro de desplazamiento afín. |
| patch\_embed.conv\_down.1.running\_mean | nn.BatchNorm2d (![][image15]) | Estadística móvil de media inferida durante el entrenamiento. |
| patch\_embed.conv\_down.1.running\_var | nn.BatchNorm2d (![][image16]) | Estadística móvil de varianza inferida durante el entrenamiento. |
| patch\_embed.conv\_down.3.weight | nn.Conv2d (![][image12], stride 2, padding 1\) | Extensión dimensional secundaria a la capacidad completa dim. Sin sesgo. |
| patch\_embed.conv\_down.4.weight | nn.BatchNorm2d (![][image13]) | Parámetro de escalado de la segunda etapa de normalización. |
| patch\_embed.conv\_down.4.bias | nn.BatchNorm2d (![][image14]) | Parámetro de desplazamiento de la segunda etapa de normalización. |
| patch\_embed.conv\_down.4.running\_mean | nn.BatchNorm2d (![][image15]) | Estadística móvil de la media final del incrustador. |
| patch\_embed.conv\_down.4.running\_var | nn.BatchNorm2d (![][image16]) | Estadística móvil de la varianza final del incrustador. |

El escrutinio de estas claves revela que el módulo de incrustación prioriza la normalización estricta sobre la aplicación de activaciones afines con sesgo. Los descriptores numéricos discretos (0, 1, 3, 4\) reflejan los índices internos posicionales generados implícitamente por el contenedor nn.Sequential de PyTorch al compilar la gráfica, donde el índice 2 corresponde al operador inyectivo de rectificación (ReLU), el cual no posee componentes paramétricos.

### **Módulos de Transición y Submuestreo Espacial (Downsample)**

A lo largo de las cuatro macroetapas jerárquicas del modelo, la resolución espacial de los mapas de características se contrae, duplicando en contrapartida la dimensionalidad de los canales semánticos. Las fronteras entre estas etapas están interconectadas mediante el módulo Downsample.9 El código fuente define una función de reducción que opera de manera determinista utilizando una operación convolucional con tamaño de núcleo ![][image12], un paso iterativo de ![][image17] y un relleno perimetral de ![][image18].17

Al iterar sobre la estructura del diccionario, estos módulos residen semánticamente en el mismo nivel jerárquico que los bloques generativos, usualmente integrados dentro de la definición paramétrica de los levels. Sin embargo, las iteraciones de la red que no aplican contracción condicional omiten este bloque instanciándolo como tipo nulo.18 La parametrización concreta se delega a un submódulo reduction.

| Prefijo Exacto del state\_dict PyTorch | Instanciación de Clase Subyacente | Función Matemática y Dimensionalidad |
| :---- | :---- | :---- |
| levels.\[i\].downsample.reduction.0.weight | nn.Conv2d (![][image12], stride 2, padding 1\) | Tensor principal que efectúa la transmutación multiescala inter-capa. Carece de parámetros de sesgo debido a normativas arquitectónicas posteriores (bias=False). El índice \[i\] oscila de 0 a 2, indicando la etapa precursora. |

### **Etapas Tempranas de Extracción: Bloques Convolucionales (ConvBlock)**

La divergencia más pronunciada entre MambaVision y los enfoques puramente Transformer radica en la comprensión de que las etapas incipientes operan sobre mapas de características de alta densidad espacial, donde la autoatención impone cuellos de botella intratables debido a su escalamiento cuadrático ![][image19] donde ![][image20].9 En consecuencia, MambaVision implementa módulos ConvBlock residuales en sus dos primeros niveles (etapa 1 y etapa 2).9

El flujo lógico del código oficial especifica la creación de un nn.ModuleList bajo el nombre self.levels. Una condición determinista (conv \= True if (i \== 0 or i \== 1\) else False) dirige al enrutador de red para instanciar bloques estrictamente convolucionales en estas iteraciones.17 Cada bloque encapsula un camino convolucional de dos fases. La primera iteración expande o procesa la representación utilizando un núcleo de convolución espacial de vecindad ![][image12], y es estabilizada mediante una normalización de lote acoplada a una activación no lineal Gaussiana aproximada (GELU). Un segundo paso homólogo cierra el ciclo antes de la suma residual integrativa.17

| Prefijo Exacto del state\_dict PyTorch | Instanciación de Clase Subyacente | Función Matemática y Dimensionalidad |
| :---- | :---- | :---- |
| levels.\[i\].blocks.\[j\].conv1.weight | nn.Conv2d (![][image12], stride 1, padding 1\) | Extractor inicial de características locales en el bloque residual. |
| levels.\[i\].blocks.\[j\].conv1.bias | Parámetro escalar unidimensional | Desplazamiento aditivo posterior a la convolución. |
| levels.\[i\].blocks.\[j\].norm1.weight | nn.BatchNorm2d (![][image13]) | Ponderador de escalamiento dinámico post-activación preliminar. |
| levels.\[i\].blocks.\[j\].norm1.bias | nn.BatchNorm2d (![][image14]) | Ponderador de desplazamiento dinámico de la representación. |
| levels.\[i\].blocks.\[j\].norm1.running\_mean | nn.BatchNorm2d (![][image15]) | Traza estadística de las activaciones pre-normalizadas. |
| levels.\[i\].blocks.\[j\].norm1.running\_var | nn.BatchNorm2d (![][image16]) | Traza de la dispersión variacional de la distribución latente. |
| levels.\[i\].blocks.\[j\].conv2.weight | nn.Conv2d (![][image12], stride 1, padding 1\) | Segunda proyección espacial del bloque, completando la función del receptor local. |
| levels.\[i\].blocks.\[j\].conv2.bias | Parámetro escalar unidimensional | Vector de sesgo afín de la segunda convolución. |
| levels.\[i\].blocks.\[j\].norm2.weight | nn.BatchNorm2d (![][image13]) | Ponderador de escalamiento previo a la adición del atajo residual. |
| levels.\[i\].blocks.\[j\].norm2.bias | nn.BatchNorm2d (![][image14]) | Desplazador afín correspondiente a la fase terminal del bloque. |
| levels.\[i\].blocks.\[j\].norm2.running\_mean | nn.BatchNorm2d (![][image15]) | Estadística de media correspondiente a la rama convolucional de salida. |
| levels.\[i\].blocks.\[j\].norm2.running\_var | nn.BatchNorm2d (![][image16]) | Estadística de varianza retenida durante los pases de optimización. |

En esta fase de extracción arquitectónica, el identificador \[i\] pertenece al conjunto ![][image21] denotando las etapas iniciales, mientras que \[j\] representa la profundidad secuencial del bloque convolucional dentro de la etapa correspondiente, guiado por la variable de configuración depths.17

### **Etapas Híbridas Profundas: MambaVisionMixer y TransformerBlock**

La innovación cardinal del modelo reside en la arquitectura de las etapas 3 y 4\. Al haber mitigado la resolución espacial a hiper-dimensiones computacionalmente asimilables, el diseño amalgama el modelado secuencial lineal de Mamba con la capacidad auto-atencional canónica del Transformer.9 De forma determinista, dado un conteo de capas ![][image22], las primeras ![][image23] capas emplean la lógica MambaVisionMixer, mientras que las subsiguientes ![][image23] aplican el bloque genérico de TransformerBlock.9 Esta hibridación supera empíricamente el rendimiento de los bloques puros, equilibrando la retención de dependencia temporal de los SSMs discretizados y el alcance sináptico iterativo de las consultas, claves y valores atencionales.

#### **Escrutinio del Módulo MambaVisionMixer**

El bloque MambaVisionMixer es un rediseño de la infraestructura original de Mamba ajustado para procesar un espacio latente de imágenes carente de asimetría direccional causal. En la teoría original de Mamba en el procesamiento del lenguaje natural, las activaciones se evaluaban restrictivamente sobre horizontes pasados.4 MambaVision altera este paradigma aplicando transformaciones convolucionales con extensiones espaciales reflectivas y simétricas.10

La inspección del algoritmo de pseudo-código proporciona un plano anatómico perfecto de la inyección paramétrica generada en PyTorch.9 El flujo se inicia con un mapeo lineal in\_proj que expande el espacio vectorial de entrada por un factor multiplicativo (frecuentemente ![][image17]) y divide la topología en dos ramas funcionales independientes: la rama ![][image24] y la rama de control ![][image25].9 Ambos tensores atraviesan independientemente proyecciones convolucionales espaciales no causales, etiquetadas en el núcleo como conv1d\_x y conv1d\_z, respectivamente.9

La rama principal procede hacia una proyección densa de dependencia selectiva x\_proj, el núcleo absoluto de la operación Mamba, emitiendo dinámicamente los parámetros latentes del espacio temporal continuo (los desplazamientos iterativos ![][image26], y las matrices condicionales ![][image5] y ![][image6]) en base al contenido de la imagen de entrada.4 Para estabilizar el operador de transición continuo intrínseco de los SSMs, la matriz central del sistema ![][image4] no se formula como un hiperparámetro no dinámico lineal, sino que es calculada a partir de su logaritmo paramétrico parametrizado estáticamente como el tensor libre de decaimiento escalar A\_log.4 A continuación se catalogan exhaustivamente los parámetros de este subsistema.

| Prefijo Exacto del state\_dict PyTorch | Instanciación de Clase Subyacente | Función Matemática y Dimensionalidad |
| :---- | :---- | :---- |
| levels.\[i\].blocks.\[j\].mixer.in\_proj.weight | nn.Linear (Dense) | Expansor inicial paramétrico. Mapea el flujo unidimensional original a dos hemisferios expansivos de procesamiento. |
| levels.\[i\].blocks.\[j\].mixer.in\_proj.bias | Tensor unidimensional | Ponderación de desplazamiento inicial. |
| levels.\[i\].blocks.\[j\].mixer.conv1d\_x.weight | nn.Conv1d (![][image27], padding 'same', grupos) | Modelado causal de la dinámica espacial en la rama de información. Ejecutado como una convolución de profundidad 1D (grouped convolution). |
| levels.\[i\].blocks.\[j\].mixer.conv1d\_x.bias | Tensor unidimensional | Sesgo aplicado a la ruta principal post-convolución. |
| levels.\[i\].blocks.\[j\].mixer.conv1d\_z.weight | nn.Conv1d (![][image27], padding 'same', grupos) | Modelado de la compuerta analítica (gating branch) operada bajo un esquema simétrico al principal. |
| levels.\[i\].blocks.\[j\].mixer.conv1d\_z.bias | Tensor unidimensional | Sesgo aplicativo de la ruta de compuerta. |
| levels.\[i\].blocks.\[j\].mixer.x\_proj.weight | nn.Linear (Dense) | Reducción dimensional para emitir los selectores locales específicos ![][image28]. Carece de desplazamiento (bias=False). |
| levels.\[i\].blocks.\[j\].mixer.dt\_proj.weight | nn.Linear (Dense) | Escalamiento de la dimensión del horizonte de tiempo continuo ![][image26]. |
| levels.\[i\].blocks.\[j\].mixer.dt\_proj.bias | Tensor unidimensional | Inicializado mediante una distribución pseudo-aleatoria exponencial; no debe re-inicializarse bajo contingencias estocásticas ordinarias. |
| levels.\[i\].blocks.\[j\].mixer.A\_log | Parámetro Tensor libre (nn.Parameter) | Formulación matemática que dicta las restricciones diagonales del espacio de estado estable, preservando la convergencia a largo plazo de la señal espacial. |
| levels.\[i\].blocks.\[j\].mixer.D | Parámetro Tensor libre (nn.Parameter) | Componente de salto iterativo escalar asimilado para inyecciones residuales directas durante la ejecución secuencial o computación de escaneo paralelo. |
| levels.\[i\].blocks.\[j\].mixer.out\_proj.weight | nn.Linear (Dense) | Contracción del sumatorio ponderado para igualar las dimensiones semánticas del tensor de escape hacia la siguiente capa de la macroarquitectura. |
| levels.\[i\].blocks.\[j\].mixer.out\_proj.bias | Tensor unidimensional | Sesgo unificador de la salida topológica Mamba. |

#### **Escrutinio del Módulo TransformerBlock**

Los bloques residuales del espectro posterior de los niveles 3 y 4 emplean una arquitectura de bloque de autoatención Multi-Cabezal (Multi-Head Self-Attention). Las representaciones espaciales transpuestas ingresan a mecanismos que generan iterativamente vectores empaquetados de Consulta (Query), Clave (Key) y Valor (Value), típicamente agrupados bajo la estructura singular qkv.18

| Prefijo Exacto del state\_dict PyTorch | Instanciación de Clase Subyacente | Función Matemática y Dimensionalidad |
| :---- | :---- | :---- |
| levels.\[i\].blocks.\[j\].attn.qkv.weight | nn.Linear (Dense) | Proyector aglomerado tridimensional que deriva conjuntamente las representaciones Query, Key y Value. |
| levels.\[i\].blocks.\[j\].attn.qkv.bias | Tensor unidimensional | Sesgo aplicable a las proyecciones conjuntas latentes de atención. |
| levels.\[i\].blocks.\[j\].attn.proj.weight | nn.Linear (Dense) | Unificador proyectivo posterior a la agregación softmax de la puntuación atencional de múltiples cabezales. |
| levels.\[i\].blocks.\[j\].attn.proj.bias | Tensor unidimensional | Vector de desplazamiento residual post-atención. |
| levels.\[i\].blocks.\[j\].mlp.fc1.weight | nn.Linear (Dense) | Extractor multiplicativo del bloque perceptrón multicapa integrado. |
| levels.\[i\].blocks.\[j\].mlp.fc1.bias | Tensor unidimensional | Desplazamiento de activación intermedio del bloque denso. |
| levels.\[i\].blocks.\[j\].mlp.fc2.weight | nn.Linear (Dense) | Contracción de dimensionalidad del bloque generador de representaciones. |
| levels.\[i\].blocks.\[j\].mlp.fc2.bias | Tensor unidimensional | Sesgo terminal previo al sumatorio residual. |

### **Cabezal Global Clasificador (Head)**

Después de iterar sobre el complejo entramado de la jerarquía multiescala, el mapa de características tridimensional final es aplanado utilizando una capa de acumulación global iterativa, formulada computacionalmente como un AdaptiveAvgPool2d.17 El vector lineal final emitido atraviesa una capa de normalización de lotes global de estabilización final y, posteriormente, una interconexión densa final para la predicción del espacio de clases (usualmente correspondiente a los ![][image29] logit paramétricos del corpus visual de ImageNet).18

Las claves del state\_dict correspondientes a este desenlace anatómico se muestran a continuación.

| Prefijo Exacto del state\_dict PyTorch | Instanciación de Clase Subyacente | Función Matemática y Dimensionalidad |
| :---- | :---- | :---- |
| norm.weight | nn.BatchNorm2d (![][image13]) | Escalador universal de las distribuciones pre-activadas. |
| norm.bias | nn.BatchNorm2d (![][image14]) | Desplazamiento aditivo universal previo al cabezal denso. |
| norm.running\_mean | nn.BatchNorm2d (![][image15]) | Esperanza estadística terminal retenida sobre lotes promediados. |
| norm.running\_var | nn.BatchNorm2d (![][image16]) | Distribución hiper-variacional terminal capturada. |
| head.weight | nn.Linear (Dense) | Proyección lineal masiva desde el hiper-espacio dimensional latente a los logit categóricos de clasificación fina. |
| head.bias | Tensor unidimensional | Ajuste basal aditivo iterativo por cada categoría final predicha. Si se especifica la variable num\_classes \= 0 (modo de extracción pura de características), este componente se convierte en una identidad morfológica sin componentes extraíbles en el estado. |

## **Fundamentos Matemáticos y Principios de Migración Transdimensional**

La arquitectura inter-procedimental de MambaVision expone un desafío infraestructural: la carga de los tensores decodificados directamente desde PyTorch hacia los grafos computacionales constructivos en ecosistemas de Keras 3 impone violaciones morfológicas inherentes. Keras 3 es un marco de nivel superior que exige rigurosidad en la definición direccional de sus operaciones, priorizando el rendimiento optimizado para backends de Álgebra Lineal Acelerada (XLA) y el diseño centrado en canales asimilables (channels-last representation).15 Por su parte, la especificación en memoria de PyTorch favorece intrínsecamente formatos centrados en el lote de dimensiones precursoras (channels-first) y asume un convenio puramente escalar para el diseño geométrico de matrices transpuestas en proyecciones densas.27

La mera inyección programática mediante métodos como target\_model.set\_weights(torch\_weights) sin manipulaciones intermedias degenera irrefutablemente en colapsos algebraicos catastróficos o activaciones distorsionadas sin propagar excepciones semánticas inmediatas, socavando el propósito del rendimiento multi-entorno.29 Las desviaciones en las convenciones se explican y mitigan mediante axiomas de transposición topológica estricta documentados iterativamente.

### **Ecuaciones de Transposición Tensorial para Proyecciones Lineales (Capas Densas)**

La capa fundacional nn.Linear de PyTorch especifica el operador matemático primario sobre su vector dimensional de pesos, denotado como ![][image30]. Durante la instanciación teórica abstracta, un proyector de ![][image31] características preexistentes a ![][image32] características de destino es moldeado como una matriz hiper-espacial bidimensional con el orden subyacente de forma ![][image33]. La ecuación de inferencia para un tensor de activación multivariante ![][image34] es evaluada formalmente mediante una multiplicación por la transpuesta del estado retenido en memoria más el corolario afín del vector de desviación ![][image35] 30:

![][image36]  
El constructor subyacente del backend de Keras 3 para su entidad abstracta keras.layers.Dense invierte la proposición inicial de alojamiento en memoria, definiendo que la manifestación paramétrica central ![][image37] debe estructurarse intrínsecamente respetando el horizonte direccional de ![][image38]. La operación del núcleo convolucional en el interior del compilador estático XLA omite cualquier transposición computacional extraña iterando en lugar del enfoque aditivo canónico:

![][image39]  
La correlación estricta para lograr consistencia e isomorfismo entre los espacios abstractos de ambos sistemas demanda una reconfiguración previa de inyección. La aserción matemática impone que la matriz proyectada del sistema de destino sea la equivalente transpuesta de su originaria de inferencia 32:

![][image40]  
En la construcción de migración computacional operada por NumPy, este principio ineludible se soluciona ejecutando una directiva de ordenamiento explícita sobre los índices axiales: np.transpose(tensor\_pytorch, (1, 0)). Los tensores suplementarios encapsulados como descriptores de sesgo (![][image35]) son estructuras planas carentes de un vector direccional bidimensional y se transmutan a ![][image41] de manera analítica directa sin incurrir en transformaciones espaciales redundantes. Esta norma de transposición subyace no solamente a los cabezales terminales sino de manera prevalente a las abstracciones paramétricas del SSM: in\_proj, x\_proj, dt\_proj, y out\_proj.

### **Ecuaciones de Alteración de Ejes para Redes Convolucionales 2D (Conv2D)**

La disparidad geométrica alcanza su cénit arquitectónico en los dominios del procesamiento de visión multivariada. PyTorch optimiza sus librerías de enlace dinámico CUDA (cuDNN) asumiendo por diseño originario un esquema computacional ![][image42] (Lote, Canal, Altura, Anchura). La implicación para su bloque instanciable nn.Conv2d genera una especificación de forma estricta que engloba cuatro coordenadas vectoriales indexadas secuencialmente como canales salientes, canales entrantes, y las coordenadas cartesianas espaciales iterativas del campo receptivo: ![][image43].27

El paradigma implementado en TensorFlow y Keras adopta universalmente la convención topológica abstracta de ![][image44] (Lote, Altura, Anchura, Canal). Las representaciones convolutivas subyacentes se ven forzadas a acomodar una disposición radicalmente opuesta para maximizar la lectura en memoria de las estructuras contiguas de la CPU y la GPU. El tensor de ponderación equivalente ![][image37] asume el orden normativo de la morfología espacial primaria seguida incondicionalmente por la conectividad de inter-canales de expansión: ![][image45].26

La igualación de ambos subespacios de parámetros demanda que el tensor cuadridimensional ![][image30] se permute axiomáticamente mediante un esquema de redistribución cruzada que migre los índices perimetrales a posiciones nucleares y viceversa. Se formula matemáticamente un operador discreto de permutación tensorial ![][image46]:

![][image47]  
El operador ![][image48] designa computacionalmente que la coordenada original emplazada en el índice 2 (eje de Altura topológica) avance jerárquicamente a la primera posición (índice 0). Recíprocamente, el índice 3 original (eje de Anchura topológica) asume la segunda iteración de anidamiento (índice 1). La dimensión contenedora del volumen de canales de entrada migra hacia atrás al índice 2, y, finalmente, la profundidad del filtro proyector de salida (originalmente posicionado en la cima geométrica) finaliza el mapeo colapsando a la posición terminal en la jerarquía (índice 3).

El corolario algorítmico explícito invoca la macro funcional np.transpose(tensor\_pytorch, (2, 3, 1, 0)) para cada manifestación dimensional paramétrica derivada de los módulos PatchEmbed, Downsample, y la rama interna total de componentes ConvBlock y sus proyecciones afines incipientes.28

### **Restructuración Dinámica de Convoluciones Temporales Unidimensionales (Conv1D)**

La particular hibridación analítica introducida en MambaVision es el abandono parcial del procesamiento denso genérico para incrustar procesadores espaciales agrupados que actúan como operadores atencionales sobre secuencias espaciales aplanadas temporalmente. Estas redes integradas en las abstracciones del MambaVisionMixer (conv1d\_x y conv1d\_z) procesan sobre la dimensión de la representación secuencial.9

Para una matriz unidimensional de tamaño de núcleo expansivo ![][image49], nn.Conv1d en PyTorch construye una infraestructura tensorial de tres parámetros ordenada estrictamente bajo el formato ![][image50]. Su homólogo natural dentro de Keras 3 altera esta proposición teórica asignando preponderancia computacional secuencial a la dimensión del núcleo, instanciando un campo jerárquico paramétrico moldeado como ![][image51].

La transición lógica del tensor extraído del marco pre-entrenado se somete a una corrección de desplazamiento iterativo que reasigna todas y cada una de las coordenadas cartesianas abstractas:

![][image52]  
Traducido, la coordenada de convolución unidireccional adopta un protagonismo inicial, el volumen de entrada se preserva inmutable en el centro hiper-espacial, y el espectro total de profundidad convolucional concluye el modelo representacional en el índice iterativo final. Programáticamente, se aplica np.transpose(tensor\_pytorch, (2, 1, 0)) a todo prefijo interceptado que contenga la denominación léxica de convolución agrupada 1D.32

### **Consolidación Secuencial Discreta en Normalización de Lotes (BatchNorm)**

Los estabilizadores numéricos conocidos en la literatura científica como Capas de Normalización por Lotes (Batch Normalization) no se sujetan a restricciones de transposición paramétrica dado que sus tensores subyacentes son vectores escalares unidimensionales.17 La divergencia insidiosa, sin embargo, radica enteramente en el comportamiento metodológico de la Programación Orientada a Objetos inherente en los procesos de carga subyacentes en cada infraestructura (Layer-based model vs. Parameter-based model).34

En la manipulación abstracta intra-sesión del flujo continuo, PyTorch dispersa los pesos normalizadores afines del modelo como entidades autónomas desvinculadas jerárquicamente dentro del state\_dict, requiriendo búsquedas léxicas exhaustivas de descriptores secuenciales predefinidos (weight, bias, running\_mean, running\_var).34 Keras 3 es estructuralmente dogmático durante la asignación externa en masa de los componentes iterativos pre-entrenados, encapsulando las estadísticas computacionales obligatoriamente a través de un arreglo matricial acoplado de cuatro dimensiones vectoriales agrupadas.34

Para una inyección exitosa y libre de colapsos topológicos asimétricos al emplear la función enlazada Layer.set\_weights(\[parametros\]), la matriz en PyTorch se empaqueta iterativamente concatenando de manera determinista un orden sub-espacial inmutable de componentes escalares, descrita en la teoría como \[gamma, beta, moving\_mean, moving\_variance\], donde gamma equivale axiomáticamente a los pesos afines restrictivos y beta mapea de manera paramétrica lineal al desplazamiento del sesgo escalar inicial.34

### **Transmutación Homóloga de Variables de Estado Mamba (A\_log y D)**

La naturaleza innovadora del Modelo Lineal Invariante en el Tiempo (SSM) introduce componentes que trascienden el marco normativo de las proyecciones afines multidimensionales canónicas y los núcleos convolucionales paramétricos.4 Durante la discretización del estado de entrada (Zero-order hold continuous discretization), variables intrínsecas del operador de inferencia analítico se preservan y modifican iterativamente, de las cuales emergen entidades clave como A\_log (una restricción representacional logarítmica para conservar autovalores continuos negativos, mitigando inestabilidades explosivas numéricas) y D (el parámetro residual inter-estado de las señales de entrada continuas).4

Dada su formulación como vectores incondicionales libres o escalares multidimensionales expandidos carentes de un flujo subespacial iterativo en PyTorch (representados como nn.Parameter independientes explícitamente), la correspondencia entre backends mantiene un isomorfismo total de uno a uno.18 Los tensores aislados durante la carga estructural carecen de cualquier necesidad axiológica de reorientación matricial bidimensional o espacial. El proceso final implica inyectar las dimensiones idénticas extraídas y procesarlas iterativamente en los contenedores receptivos generados asimilando el mismo paradigma topológico.

## **Diccionario Analítico de Traducción Léxica y Mapeo Computacional**

La convergencia holística y la transposición determinista entre ambos marcos se plasma formalmente en el presente diccionario de traducción computacional. La tabla expuesta detalla sin fisuras los clústeres originarios intra-sistema correspondientes al estado pre-compilado en CUDA, mapeados intrínsecamente a su designación funcional asimilada para una implementación Keras 3 modular robusta, especificando iterativamente la formulación transdimensional aplicada sobre la carga en memoria compartida.

| Agrupación de Módulos | Prefijo/Sufijo Origen PyTorch (state\_dict\_key) | Módulo de Destino Keras 3 (Propuesto) | Estructura Listada Keras y Alteración Transposicional Aplicada |
| :---- | :---- | :---- | :---- |
| **A. PatchEmbed (Incrustador de Tokens Espaciales)** | patch\_embed.conv\_down.0.weight | PatchEmbed.conv\_down\_0 (Conv2D) | Tensor Único \[Kernel\]. **Permutación:** np.transpose(T, (2, 3, 1, 0)) |
|  | patch\_embed.conv\_down.1.\* | PatchEmbed.norm\_1 (BatchNorm2D) | Lista Agrupada \[w, b, rm, rv\]. **Permutación:** Asimilación escalar inalterada. |
|  | patch\_embed.conv\_down.3.weight | PatchEmbed.conv\_down\_3 (Conv2D) | Tensor Único \[Kernel\]. **Permutación:** np.transpose(T, (2, 3, 1, 0)) |
|  | patch\_embed.conv\_down.4.\* | PatchEmbed.norm\_4 (BatchNorm2D) | Lista Agrupada \[w, b, rm, rv\]. **Permutación:** Asimilación escalar inalterada. |
| **B. Módulos de Reducción Jerárquica Inter-Etapa (Downsample)** | levels.\*.downsample.reduction.0.weight | Downsample.reduction\_0 (Conv2D) | Tensor Único \[Kernel\]. **Permutación:** np.transpose(T, (2, 3, 1, 0)) |
| **C. Bloques Residuales Convolucionales Puros (Stages 1-2)** | levels.\*.blocks.\*.conv1.weight & .bias | ConvBlock.conv1 (Conv2D) | \[kernel, bias\]. **Permutación del Kernel:** np.transpose(T, (2, 3, 1, 0)) |
|  | levels.\*.blocks.\*.norm1.\* | ConvBlock.norm1 (BatchNorm2D) | Lista Agrupada \[w, b, rm, rv\]. **Permutación:** Ninguna. |
|  | levels.\*.blocks.\*.conv2.weight & .bias | ConvBlock.conv2 (Conv2D) | \[kernel, bias\]. **Permutación del Kernel:** np.transpose(T, (2, 3, 1, 0)) |
|  | levels.\*.blocks.\*.norm2.\* | ConvBlock.norm2 (BatchNorm2D) | Lista Agrupada \[w, b, rm, rv\]. **Permutación:** Ninguna. |
| **D. Bloques del Mezclador de Espacio de Estados (MambaVisionMixer)** | levels.\*.blocks.\*.mixer.in\_proj.weight & .bias | MambaMixer.in\_proj (Dense) | \[kernel, bias\]. **Permutación del Kernel:** np.transpose(T, (1, 0)) |
|  | levels.\*.blocks.\*.mixer.x\_proj.weight | MambaMixer.x\_proj (Dense) | Tensor Único \[Kernel\] sin bias. **Permutación del Kernel:** np.transpose(T, (1, 0)) |
|  | levels.\*.blocks.\*.mixer.conv1d\_x.weight & .bias | MambaMixer.conv1d\_x (Conv1D) | \[kernel, bias\]. **Permutación del Kernel:** np.transpose(T, (2, 1, 0)) |
|  | levels.\*.blocks.\*.mixer.conv1d\_z.weight & .bias | MambaMixer.conv1d\_z (Conv1D) | \[kernel, bias\]. **Permutación del Kernel:** np.transpose(T, (2, 1, 0)) |
|  | levels.\*.blocks.\*.mixer.dt\_proj.weight & .bias | MambaMixer.dt\_proj (Dense) | \[kernel, bias\]. **Permutación del Kernel:** np.transpose(T, (1, 0)) |
|  | levels.\*.blocks.\*.mixer.A\_log | MambaMixer.A\_log (Layer/Variable) | Variable Directa. **Permutación:** Copia paramétrica asimétrica inalterada. |
|  | levels.\*.blocks.\*.mixer.D | MambaMixer.D (Layer/Variable) | Variable Directa. **Permutación:** Copia paramétrica asimétrica inalterada. |
|  | levels.\*.blocks.\*.mixer.out\_proj.weight & .bias | MambaMixer.out\_proj (Dense) | \[kernel, bias\]. **Permutación del Kernel:** np.transpose(T, (1, 0)) |
| **E. Cabezal Proyectivo Global de Clasificación Semántica (Head)** | norm.\* | Model.head\_norm (BatchNorm2D) | Lista Agrupada \[w, b, rm, rv\]. **Permutación:** Ninguna. |
|  | head.weight & .bias | Model.head (Dense) | \[kernel, bias\]. **Permutación del Kernel:** np.transpose(T, (1, 0)) |

## **Algoritmia Estructural y Orquestación Computacional de la Transferencia**

Una simple inferencia de traducción de utilidades abstractas generalistas (como pt2keras) no garantiza fiabilidad empírica debido a la particular naturaleza exótica y acoplada del núcleo iterativo computacional selective\_scan\_fn.14 Es imprescindible un proceso asimilativo determinista programado analíticamente paso a paso, abordando las inconsistencias inter-sistemas para asegurar una preservación total de las distribuciones latentes subyacentes sin colapsar el entorno JAX, TensorFlow o Torch agnóstico que gestiona el ecosistema Keras 3\.15

El algoritmo delineado a continuación se bifurca en un flujo metodológico lógico y cohesivo compuesto por fases consecutivas inmutables:

1. **Fase de Decodificación Cautelosa y Purga Metadática**: Para evitar excepciones perjudiciales de deserialización generadas por hiperparámetros de CUDA subyacentes que puedan no estar presentes en clústeres heterogéneos, se extraen las directivas seriales mapeando universalmente todo objeto a la unidad lógica abstracta (CPU).16 Con el núcleo consolidado, la limpieza algorítmica itera para suprimir los constructos paralelos de infraestructura multitarjeta, despojando al léxico de cualquier ocurrencia destructiva del infame prefijo module. y de contenedores analíticos prescindibles como iteraciones semánticas encoder..17 Asimismo, se omiten explícitamente fragmentos contadores estocásticos (num\_batches\_tracked) dado que envenenan las directrices esperadas de variables de Keras 3 durante el modelado secuencial de lotes.  
2. **Fase Heurística Transposicional Continua**: Un motor subyacente de agrupamiento explora heurísticamente las dimensionalidades retenidas por cada subcampo. Basándose en la magnitud tridimensional del vector numérico y analizando sufijos específicos léxicos (.weight asociado a contextos nominales de convolución intraespacial), procesa y aplica la pertinente operación transdimensional formulada mediante una rotación de tensores en memoria continua de NumPy. Paralelamente, empaqueta las constantes de dispersión afín (escalas, desplazamientos, varianzas temporales) para condensarlas sin fisuras dimensionales hacia las construcciones matriciales estáticas pre-empaquetadas.32  
3. **Fase Condicional Previa a la Ejecución Constructiva Keras 3**: Keras 3, a diferencia de versiones predecesoras abstractas menos astringentes asociadas exclusivamente a backends unificados limitados, castiga rigurosamente las definiciones estructurales diferidas debido al marco universal requerido por JAX. Un intento por sobrescribir hiper-variables tensoriales inexactas antes de procesar el recorrido del grafo completo produce aserciones irrecuperables de NotImplementedError o inestabilidad in-place.15 De ahí que se ejecute axiomáticamente una iteración ficticia generativa (dummy forward pass) predeterminada antes de asimilar el modelo decodificado.15  
4. **Fase Top-Down de Ensamblaje Paramétrico Físico**: Habiendo verificado y solidificado exhaustivamente el marco Keras, la infusión se canaliza en bloque recorriendo jerárquicamente las abstracciones léxicas de la clase. Cada tensor es reasignado mediante un mapeado inyectivo inquebrantable empleando el método fundamental .set\_weights() para el compendio genérico, y rutinas aditivas (.assign()) para las métricas invariables del espacio SSM latente.29

### **Implementación del Script de Migración en Python**

La síntesis metodológica detallada previamente converge en la siguiente instrumentación de software. Se presupone computacionalmente que las estructuras híbridas de nivel abstracto equivalentes (PatchEmbed, MambaVisionLayer, ConvBlock, MambaVisionMixer, Downsample) han sido instanciadas en un envoltorio primario heredado explícitamente como clase desde keras.Model.

Python

import torch  
import numpy as np  
import keras  
from collections import defaultdict

def decodificar\_y\_purgar\_estado\_pytorch(ruta\_checkpoint: str) \-\> dict:  
    """  
    Rutina de deserialización segura que purga la topología de diccionarios de   
    PyTorch de descriptores paralelos irrelevantes para asimilaciones estáticas.  
    """  
    \# Restricción explícita de seguridad analítica forzando carga en memoria general  
    checkpoint \= torch.load(ruta\_checkpoint, map\_location='cpu', weights\_only=True)  
      
    \# Resolver jerarquías de encapsulamiento estocásticas en serialización  
    if 'state\_dict' in checkpoint:  
        estado\_diccionario \= checkpoint\['state\_dict'\]  
    elif 'model' in checkpoint:  
        estado\_diccionario \= checkpoint\['model'\]  
    else:  
        estado\_diccionario \= checkpoint  
          
    estado\_limpio \= {}  
    for llave\_identificadora, tensor\_valor in estado\_diccionario.items():  
        \# Extracción y supresión procedimental de artefactos DDP y prefijos base  
        llave\_procesada \= llave\_identificadora.replace('module.', '').replace('encoder.', '')  
              
        \# Purgado riguroso de iteradores contadores internos asimilables por la lógica  
        if 'num\_batches\_tracked' in llave\_procesada:  
            continue  
              
        \# Destrucción del grafo dinámico tensor subyacente de Torch   
        \# para aislar el campo puramente estático de tensores NumPy multidimensionales  
        estado\_limpio\[llave\_procesada\] \= tensor\_valor.numpy()  
          
    return estado\_limpio

def evaluar\_y\_mutar\_dimensionalidad(llave: str, tensor: np.ndarray) \-\> np.ndarray:  
    """  
    Motor heurístico evaluador para transmutar geométricamente las especificaciones   
    matrices de PyTorch a los imperativos dogmáticos multidimensionales de Keras 3\.  
    """  
    conteo\_dimensional \= len(tensor.shape)  
      
    \# Regla 1: Alteración Espacial de Convoluciones 2D Puras   
    \# Formulación transdimensional: (C\_out, C\_in, H, W) \-\> (H, W, C\_in, C\_out)  
    if conteo\_dimensional \== 4:  
        return np.transpose(tensor, (2, 3, 1, 0))  
      
    \# Regla 2: Alteración Topológica de Convoluciones Secuenciales y Espaciales 1D  
    \# Formulación transdimensional Mamba Mixer: (C\_out, C\_in, K) \-\> (K, C\_in, C\_out)  
    elif conteo\_dimensional \== 3 and 'conv1d' in llave:  
        return np.transpose(tensor, (2, 1, 0))  
          
    \# Regla 3: Alteración Bidimensional Aislada de Estructuras Densas Lineales  
    \# Formulación transdimensional atencional: (D\_out, D\_in) \-\> (D\_in, D\_out)  
    elif conteo\_dimensional \== 2:  
        return np.transpose(tensor, (1, 0))  
          
    \# Salida nula-iterativa (Tensores de escalado normativo y tensores paramétricos crudos Mamba)  
    return tensor

def consolidar\_vectores\_normalizacion(estado\_limpio\_mutado: dict) \-\> dict:  
    """  
    Unificador asimilador que compendia los vectores de estado de   
    BatchNormalization, preensamblándolos orgánicamente.  
    """  
    diccionario\_keras\_final \= {}  
    repositorio\_normalizadores \= defaultdict(dict)  
      
    for llave\_identificadora, tensor in estado\_limpio\_mutado.items():  
        subcampos\_evaluadores \= \['.weight', '.bias', '.running\_mean', '.running\_var'\]  
        \# Desglosar condicionalmente estructuras multi-campo  
        if any(sufijo in llave\_identificadora for sufijo in subcampos\_evaluadores):  
            prefijo\_base, descriptor\_sufijo \= llave\_identificadora.rsplit('.', 1)  
              
            if descriptor\_sufijo in \['weight', 'bias', 'running\_mean', 'running\_var'\]:  
                repositorio\_normalizadores\[prefijo\_base\]\[descriptor\_sufijo\] \= evaluar\_y\_mutar\_dimensionalidad(llave\_identificadora, tensor)  
            else:  
                diccionario\_keras\_final\[llave\_identificadora\] \= evaluar\_y\_mutar\_dimensionalidad(llave\_identificadora, tensor)  
        else:  
            \# Procesamiento inquebrantable asimilativo de variables no normativas (A\_log)  
            diccionario\_keras\_final\[llave\_identificadora\] \= evaluar\_y\_mutar\_dimensionalidad(llave\_identificadora, tensor)  
              
    \# Formulación del ensamblador:  
    for prefijo\_base, grupo\_componentes in repositorio\_normalizadores.items():  
        if 'running\_mean' in grupo\_componentes:  
            gamma\_escala \= grupo\_componentes.get('weight', np.ones\_like(grupo\_componentes\['running\_mean'\]))  
            beta\_desplazamiento \= grupo\_componentes.get('bias', np.zeros\_like(grupo\_componentes\['running\_mean'\]))  
            media \= grupo\_componentes\['running\_mean'\]  
            varianza \= grupo\_componentes\['running\_var'\]  
            diccionario\_keras\_final\[prefijo\_base\] \= \[gamma\_escala, beta\_desplazamiento, media, varianza\]  
        else:  
            \# Reintegrar bloques de red desvinculados de secuencias normativas globales (Densas puras)  
            if 'weight' in grupo\_componentes:  
                diccionario\_keras\_final\[f"{prefijo\_base}.weight"\] \= grupo\_componentes\['weight'\]  
            if 'bias' in grupo\_componentes:  
                diccionario\_keras\_final\[f"{prefijo\_base}.bias"\] \= grupo\_componentes\['bias'\]  
                  
    return diccionario\_keras\_final

def efectuar\_injerto\_parametrizado(modelo\_compilado\_keras: keras.Model, ruta\_checkpoint\_pytorch: str):  
    """  
    Orquestador terminal de la propagación inyectiva de pesos desde la matriz   
    en PyTorch hacia los nodos paramétricos del modelo instanciado general en Keras 3\.  
    """  
    \# 0\. Fase mandataria del motor Keras 3 (Evaluación ficticia forzosa)  
    print(" Forzando compilación anticipada e inferencia estructurada de subgrafos...")  
    espectro\_tensor\_aleatorio \= np.random.normal(size=(1, 224, 224, 3)).astype(np.float32)  
    \_ \= modelo\_compilado\_keras(espectro\_tensor\_aleatorio)  
      
    print("\[1/3\] Extrayendo, filtrando lógicamente y esterilizando base analítica...")  
    diccionario\_base\_crudo \= decodificar\_y\_purgar\_estado\_pytorch(ruta\_checkpoint\_pytorch)  
      
    print("\[2/3\] Computando topología de convolución cruzada y resolviendo dimensiones...")  
    diccionario\_matrices\_preparadas \= consolidar\_vectores\_normalizacion(diccionario\_base\_crudo)  
      
    print("\[3/3\] Inyectando campos sinápticos y descriptores continuos asimilativos...")  
      
    \# Inyección Nivel 1: Submódulo Stem / Incrustador de Token PatchEmbed  
    modelo\_compilado\_keras.patch\_embed.conv\_down\_0.set\_weights(\[diccionario\_matrices\_preparadas\['patch\_embed.conv\_down.0.weight'\]\])  
    modelo\_compilado\_keras.patch\_embed.norm\_1.set\_weights(diccionario\_matrices\_preparadas\['patch\_embed.conv\_down.1'\])  
    modelo\_compilado\_keras.patch\_embed.conv\_down\_3.set\_weights(\[diccionario\_matrices\_preparadas\['patch\_embed.conv\_down.3.weight'\]\])  
    modelo\_compilado\_keras.patch\_embed.norm\_4.set\_weights(diccionario\_matrices\_preparadas\['patch\_embed.conv\_down.4'\])  
      
    \# Inyección Nivel 2: Módulos Iterativos y Jerarquías Inter-espaciales (Levels)  
    for indice\_etapa, capa\_nivel\_actual in enumerate(modelo\_compilado\_keras.levels):  
          
        \# Validación inyectiva direccional para bloques de Submuestreo Reductivo (Downsample)  
        if hasattr(capa\_nivel\_actual, 'downsample') and capa\_nivel\_actual.downsample is not None:  
            llave\_referencial\_reduccion \= f"levels.{indice\_etapa}.downsample.reduction.0.weight"  
            capa\_nivel\_actual.downsample.reduction\_0.set\_weights(\[diccionario\_matrices\_preparadas\[llave\_referencial\_reduccion\]\])  
              
        \# Inyección profunda en el interior iterativo del espectro bloque-a-bloque (Blocks)  
        for indice\_bloque, estructura\_bloque\_interno in enumerate(capa\_nivel\_actual.blocks):  
            prefijo\_llave\_basal \= f"levels.{indice\_etapa}.blocks.{indice\_bloque}"  
              
            \# Sub-Condición: Estructuras ConvBlock (Etapas 1 y 2 \- Extracción Temprana)  
            if hasattr(estructura\_bloque\_interno, 'conv1'):  
                estructura\_bloque\_interno.conv1.set\_weights(\[  
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.conv1.weight"\],   
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.conv1.bias"\])  
                estructura\_bloque\_interno.norm1.set\_weights(diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.norm1"\])  
                estructura\_bloque\_interno.conv2.set\_weights(\[  
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.conv2.weight"\],   
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.conv2.bias"\])  
                estructura\_bloque\_interno.norm2.set\_weights(diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.norm2"\])  
                  
            \# Sub-Condición: Estructuras Complejas del SSM (Etapas 3 y 4 \- Mezclador)  
            elif hasattr(estructura\_bloque\_interno, 'mixer'):  
                \# 1\. Tensores de proyección de rama bidireccional densa  
                estructura\_bloque\_interno.mixer.in\_proj.set\_weights(\[  
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.in\_proj.weight"\],   
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.in\_proj.bias"\])  
                \# Proyección paramétrica inyectiva sin sesgo generador  
                estructura\_bloque\_interno.mixer.x\_proj.set\_weights(\[diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.x\_proj.weight"\]\])  
                  
                \# 2\. Tensores dependientes del modelado causal analítico temporal convolucional unidimensional  
                estructura\_bloque\_interno.mixer.conv1d\_x.set\_weights(\[  
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.conv1d\_x.weight"\],   
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.conv1d\_x.bias"\])  
                estructura\_bloque\_interno.mixer.conv1d\_z.set\_weights(\[  
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.conv1d\_z.weight"\],   
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.conv1d\_z.bias"\])  
                  
                \# 3\. Proyecciones terminales hiper-variables latentes  
                estructura\_bloque\_interno.mixer.dt\_proj.set\_weights(\[  
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.dt\_proj.weight"\],   
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.dt\_proj.bias"\])  
                estructura\_bloque\_interno.mixer.out\_proj.set\_weights(\[  
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.out\_proj.weight"\],   
                    diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.out\_proj.bias"\])  
                  
                \# 4\. Asimilación Continua Directa de Variables Espaciales Sensibles Invariantes  
                \# Nota Computacional: Utilizar assign() evita reestructuraciones estocásticas de capa iterativa  
                estructura\_bloque\_interno.mixer.A\_log.assign(diccionario\_matrices\_preparadas\[f"{prefijo\_llave\_basal}.mixer.A\_log"\])  
                estructura\_bloque\_interno.mixer.D.assign(diccionario\_matrices\_preparadas)  
                  
    \# Inyección Nivel 3: Consolidador Generalizado Terminal (Clasificador y Cuello de Botella Normativo)  
    modelo\_compilado\_keras.head\_norm.set\_weights(diccionario\_matrices\_preparadas\['norm'\])  
      
    \# Restricción Condicional para modelado puramente extractivo (feature extractor backbones)  
    if hasattr(modelo\_compilado\_keras, 'head') and modelo\_compilado\_keras.head is not None:  
        if isinstance(modelo\_compilado\_keras.head, keras.layers.Dense):  
            modelo\_compilado\_keras.head.set\_weights(\[  
                diccionario\_matrices\_preparadas\['head.weight'\],   
                diccionario\_matrices\_preparadas\['head.bias'\])

    print("\[✔\] Ejecución Culminada: Arquitectura multi-backend poblada asimétrica e isomorficamente.")

## **Consideraciones Analíticas Post-Inyección y Despliegue en Borde**

La transmutación de una arquitectura híbrida vanguardista de las especificaciones rigurosas de un laboratorio académico soportado inherentemente por PyTorch a un conducto industrial universal encapsulado bajo Keras 3 es un ejercicio que sobrepasa el trivial intercambio de parámetros; es esencialmente un procedimiento quirúrgico algebraico.15 Los tensores críticos correspondientes al integrador central dinámico de tiempo continuo en MambaVision —A\_log y D— garantizan iterativamente la estabilidad representacional de las funciones subyacentes frente a inyecciones complejas en tiempo de compilación. En el instante preciso de la traducción de variables en un entorno como JAX o un compilador acelerador XLA, cualquier irregularidad bidimensional superpuesta en estos parámetros logarítmicos continuos desembocaría en desestabilización numérica catastrófica de gradientes en subsecuentes ciclos de ajuste fino iterativo (fine-tuning).9 Al asimilarlos rigurosamente a través de métodos de variable desnuda (.assign()) y no sobrecargas aglomeradas afines (.set\_weights()), la infraestructura computacional retiene el paradigma original inalterable.

El imperativo tras este colosal esfuerzo de adaptación reside no en el mero academicismo de validación cruzada, sino en la escalabilidad computacional en ambientes infraestructurales restrictivos.10 Keras 3 proporciona un pasaje natural hacia infraestructuras perimetrales de IoT de memoria restringida, procesadores tensoriales dedicados (TPUs) de Google, y unificadores de despliegue industrial multiescala al facilitar traducciones automáticas directas desde el código migrado a formatos como TensorFlow Lite o despliegues puros en infraestructuras orientadas a JAX.15 MambaVision, validado y encapsulado con un injerto anatómico estructuralmente riguroso a través del diccionario transposicional aquí provisto, transciende las limitantes conceptuales originarias de la representación matricial causal, abriendo vertientes exploratorias sin parangón en el modelado visual generalizado ultraeficiente y altamente escalable.

#### **Obras citadas**

1. myscience/mamba: Pytorch (Lightning) implementation of the Mamba model \- GitHub, fecha de acceso: febrero 26, 2026, [https://github.com/myscience/mamba](https://github.com/myscience/mamba)  
2. Mamba: SSM, Theory, and Implementation in Keras and TensorFlow, fecha de acceso: febrero 26, 2026, [https://towardsdatascience.com/mamba-ssm-theory-and-implementation-in-keras-and-tensorflow-32d6d4b32546/](https://towardsdatascience.com/mamba-ssm-theory-and-implementation-in-keras-and-tensorflow-32d6d4b32546/)  
3. Here Comes Mamba: The Selective State Space Model | Towards Data Science, fecha de acceso: febrero 26, 2026, [https://towardsdatascience.com/here-comes-mamba-the-selective-state-space-model-435e5d17a451/](https://towardsdatascience.com/here-comes-mamba-the-selective-state-space-model-435e5d17a451/)  
4. Implementing Mamba in PyTorch \- Medium, fecha de acceso: febrero 26, 2026, [https://medium.com/@torotoki/getting-started-with-mamba-implementing-mamba-in-pytorch-33d56ccd8393](https://medium.com/@torotoki/getting-started-with-mamba-implementing-mamba-in-pytorch-33d56ccd8393)  
5. Releases · NVlabs/MambaVision \- GitHub, fecha de acceso: febrero 26, 2026, [https://github.com/NVlabs/MambaVision/releases](https://github.com/NVlabs/MambaVision/releases)  
6. \[CVPR 2025\] Official PyTorch Implementation of MambaVision: A Hybrid Mamba-Transformer Vision Backbone \- GitHub, fecha de acceso: febrero 26, 2026, [https://github.com/NVlabs/MambaVision](https://github.com/NVlabs/MambaVision)  
7. \[2407.08083\] MambaVision: A Hybrid Mamba-Transformer Vision Backbone \- arXiv, fecha de acceso: febrero 26, 2026, [https://arxiv.org/abs/2407.08083](https://arxiv.org/abs/2407.08083)  
8. hustvl/Vim: \[ICML 2024\] Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model \- GitHub, fecha de acceso: febrero 26, 2026, [https://github.com/hustvl/Vim](https://github.com/hustvl/Vim)  
9. MambaVision: A Hybrid Mamba-Transformer Vision Backbone \- CVF Open Access, fecha de acceso: febrero 26, 2026, [https://openaccess.thecvf.com/content/CVPR2025/papers/Hatamizadeh\_MambaVision\_A\_Hybrid\_Mamba-Transformer\_Vision\_Backbone\_CVPR\_2025\_paper.pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Hatamizadeh_MambaVision_A_Hybrid_Mamba-Transformer_Vision_Backbone_CVPR_2025_paper.pdf)  
10. MambaVision: A Hybrid Mamba-Transformer Vision Backbone \- arXiv, fecha de acceso: febrero 26, 2026, [https://arxiv.org/html/2407.08083v1](https://arxiv.org/html/2407.08083v1)  
11. SAM-Guided Concrete Bridge Damage Segmentation with Mamba–ResNet Hierarchical Fusion Network \- MDPI, fecha de acceso: febrero 26, 2026, [https://www.mdpi.com/2079-9292/14/8/1497](https://www.mdpi.com/2079-9292/14/8/1497)  
12. nvidia/MambaVision-L-21K \- Hugging Face, fecha de acceso: febrero 26, 2026, [https://huggingface.co/nvidia/MambaVision-L-21K](https://huggingface.co/nvidia/MambaVision-L-21K)  
13. A2Mamba: Attention-augmented State Space Models for Visual Recognition \- GitHub, fecha de acceso: febrero 26, 2026, [https://github.com/LMMMEng/A2Mamba](https://github.com/LMMMEng/A2Mamba)  
14. VMamba/vmamba.py at main · MzeroMiko/VMamba \- GitHub, fecha de acceso: febrero 26, 2026, [https://github.com/MzeroMiko/VMamba/blob/main/vmamba.py](https://github.com/MzeroMiko/VMamba/blob/main/vmamba.py)  
15. Migrating Keras 2 code to multi-backend Keras 3, fecha de acceso: febrero 26, 2026, [https://keras.io/guides/migrating\_to\_keras\_3/](https://keras.io/guides/migrating_to_keras_3/)  
16. Saving and Loading Models — PyTorch Tutorials 2.10.0+cu128 documentation, fecha de acceso: febrero 26, 2026, [https://docs.pytorch.org/tutorials/beginner/saving\_loading\_models.html](https://docs.pytorch.org/tutorials/beginner/saving_loading_models.html)  
17. modeling\_mambavision.py · nvidia/MambaVision-T-1K at b1de77e17599566d98efb701c0231b1095dc3a67 \- Hugging Face, fecha de acceso: febrero 26, 2026, [https://huggingface.co/nvidia/MambaVision-T-1K/blame/b1de77e17599566d98efb701c0231b1095dc3a67/modeling\_mambavision.py](https://huggingface.co/nvidia/MambaVision-T-1K/blame/b1de77e17599566d98efb701c0231b1095dc3a67/modeling_mambavision.py)  
18. modeling\_mambavision.py · nvidia/MambaVision-B-1K at main \- Hugging Face, fecha de acceso: febrero 26, 2026, [https://huggingface.co/nvidia/MambaVision-B-1K/blob/main/modeling\_mambavision.py](https://huggingface.co/nvidia/MambaVision-B-1K/blob/main/modeling_mambavision.py)  
19. MambaVision原理和源码调测原创 \- CSDN博客, fecha de acceso: febrero 26, 2026, [https://blog.csdn.net/cskywit/article/details/142957710](https://blog.csdn.net/cskywit/article/details/142957710)  
20. modeling\_mambavision.py · nvidia/MambaVision-B-21K at ab797f065a7230f493c65bd55b2156660c0b6a40 \- Hugging Face, fecha de acceso: febrero 26, 2026, [https://huggingface.co/nvidia/MambaVision-B-21K/blame/ab797f065a7230f493c65bd55b2156660c0b6a40/modeling\_mambavision.py](https://huggingface.co/nvidia/MambaVision-B-21K/blame/ab797f065a7230f493c65bd55b2156660c0b6a40/modeling_mambavision.py)  
21. SoLA-Vision: Fine-grained Layer-wise Linear Softmax Hybrid Attention \- arXiv, fecha de acceso: febrero 26, 2026, [https://arxiv.org/html/2601.11164v1](https://arxiv.org/html/2601.11164v1)  
22. Mamba Vision \- Kaggle, fecha de acceso: febrero 26, 2026, [https://www.kaggle.com/code/tngphmvn/mamba-vision](https://www.kaggle.com/code/tngphmvn/mamba-vision)  
23. Mamba: Linear-Time Sequence Modeling with Selective State Spaces \- arXiv.org, fecha de acceso: febrero 26, 2026, [https://arxiv.org/abs/2312.00752](https://arxiv.org/abs/2312.00752)  
24. Completing the Circle: Building a MambaTransformer from Scratch \- GoPenAI, fecha de acceso: febrero 26, 2026, [https://blog.gopenai.com/completing-the-circle-building-a-mambatransformer-from-scratch-f92a02381bc8](https://blog.gopenai.com/completing-the-circle-building-a-mambatransformer-from-scratch-f92a02381bc8)  
25. Mamba Vision for deepfake detection \- Kaggle, fecha de acceso: febrero 26, 2026, [https://www.kaggle.com/code/aleksandrpikul222/mamba-vision-for-deepfake-detection](https://www.kaggle.com/code/aleksandrpikul222/mamba-vision-for-deepfake-detection)  
26. Significant differences between Keras/TensorFlow and Torch \- vision \- PyTorch Forums, fecha de acceso: febrero 26, 2026, [https://discuss.pytorch.org/t/significant-differences-between-keras-tensorflow-and-torch/181932](https://discuss.pytorch.org/t/significant-differences-between-keras-tensorflow-and-torch/181932)  
27. Converting a PyTorch Model to Keras: Let's Do It Manually | by Khayrul Islam | Perceptron Perspectives | Medium, fecha de acceso: febrero 26, 2026, [https://medium.com/perceptron-perspectives/converting-a-pytorch-model-to-keras-lets-do-it-manually-57b073d309a8](https://medium.com/perceptron-perspectives/converting-a-pytorch-model-to-keras-lets-do-it-manually-57b073d309a8)  
28. Same weights, implementation but different results n Keras and Pytorch \- Stack Overflow, fecha de acceso: febrero 26, 2026, [https://stackoverflow.com/questions/66744761/same-weights-implementation-but-different-results-n-keras-and-pytorch](https://stackoverflow.com/questions/66744761/same-weights-implementation-but-different-results-n-keras-and-pytorch)  
29. Tensorflow Keras Copy Weights From One Model to Another \- Stack Overflow, fecha de acceso: febrero 26, 2026, [https://stackoverflow.com/questions/48547688/tensorflow-keras-copy-weights-from-one-model-to-another](https://stackoverflow.com/questions/48547688/tensorflow-keras-copy-weights-from-one-model-to-another)  
30. Keras layer weights shape is different compared to other conventions, fecha de acceso: febrero 26, 2026, [https://datascience.stackexchange.com/questions/80794/keras-layer-weights-shape-is-different-compared-to-other-conventions](https://datascience.stackexchange.com/questions/80794/keras-layer-weights-shape-is-different-compared-to-other-conventions)  
31. Save and Load Your PyTorch Models \- MachineLearningMastery.com, fecha de acceso: febrero 26, 2026, [https://machinelearningmastery.com/save-and-load-your-pytorch-models/](https://machinelearningmastery.com/save-and-load-your-pytorch-models/)  
32. Transferring weights from plantnet pytorch model to keras model, fecha de acceso: febrero 26, 2026, [https://discuss.pytorch.org/t/transferring-weights-from-plantnet-pytorch-model-to-keras-model/176144](https://discuss.pytorch.org/t/transferring-weights-from-plantnet-pytorch-model-to-keras-model/176144)  
33. Transferring weights from Keras to PyTorch \- Page 2, fecha de acceso: febrero 26, 2026, [https://discuss.pytorch.org/t/transferring-weights-from-keras-to-pytorch/9889?page=2](https://discuss.pytorch.org/t/transferring-weights-from-keras-to-pytorch/9889?page=2)  
34. How to load weights from Pytorch to Keras layer by layer? \- Stack Overflow, fecha de acceso: febrero 26, 2026, [https://stackoverflow.com/questions/66715973/how-to-load-weights-from-pytorch-to-keras-layer-by-layer](https://stackoverflow.com/questions/66715973/how-to-load-weights-from-pytorch-to-keras-layer-by-layer)  
35. "Missing key(s) in state\_dict" error when loading model \- Stack Overflow, fecha de acceso: febrero 26, 2026, [https://stackoverflow.com/questions/76124928/missing-keys-in-state-dict-error-when-loading-model](https://stackoverflow.com/questions/76124928/missing-keys-in-state-dict-error-when-loading-model)  
36. migrate keras2 code to keras3.0 with pytorch backend, got inplace error · Issue \#18895 · keras-team/keras \- GitHub, fecha de acceso: febrero 26, 2026, [https://github.com/keras-team/keras/issues/18895](https://github.com/keras-team/keras/issues/18895)

[image1]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACsAAAAYCAYAAABjswTDAAADPElEQVR4Xu2WWahNURzGP/OQmQwh15DpgUiiyDW9IENmkXmeMobIA2+kiMxlLhIiMiQHGSNDikTkhbwokiLxfed/9tnrrrPPudcZHtT96lfnrLXX9J/WAsr1f6gymUTWkBpeX2mqSpaQmYnfBVUFMpKcIK28vrKqKTlAxpGKXl9adSL7yALSmWwln8hP8hBmPVnRVRE5Q4bBNp6tislV0sVrT5E2MJXcImPJRHKXbCbzyA3yh7wnvWxIXBq3gpwjTZz2bFSfHCXrSRWvLyktOItcIz3IdPKGjEFoqWawU/8mGxFO1pxcgcVcpURbttL4xTAjdfD64tJmhpNHZBDpRl7CTljH+U5xtJD8IHtJzUT7QNjYPon/uWoAeU0mICKkishtsh22udXkHunufCNp4GjyFZYI2qwOMB/2fbvw05zUmtwhG+DlhhZTPH4m4xFxEkfq02m/kU2wMKhGtsHCR9nsSuVrJcxLJ0nXxP/L5AHZBTOUL8XtWbIboffiqgVz9ztYrGaS4klW/4LwYLXJMXIBtoir/mQtGUo+kuewaiFr9YS5ehVS4zyYU+h3Ui1hLnwFK1OZ1AB24scIXa6wkdVUX92JZXFZcQgscXXARQjd2pu8RfRmZU3lxHnYmklps/dh5UinTSdZcRTMAzMQLqANHkfqZgNVJzvIC4TGUOiphn+AJZMvbXYPuUgauh36c4l8h20i3c2hgzyDXRZ1nfZgYtVYPwwklTvV59OkXqIt8JDKXVRd1qEVmqdQcq14kiiufpEnSI1bWbQv7OZSQpRwC8zdW2D1N2phXR5yt94LQQj0g3lIF0lb2AXgjtWhdBvuRMQbQ6UiBrudlOmHyDRYcZZFtJgmThkICwfForK7vdcnL82FhZhqcdA2Gzan2ubAqpFbohSa8kZUPMfViCwlN2EhEVwKUxC6L52KyVMy2GvX62kdOUIaO+1tyGFynSyD52pY8inkRiBzKc1KskQMpdznZZQ2JwPFYCGSd8mC2qguhhZe379KyaWypbdHwd61qru6mVTecnGdLhLV145+Rz6lxNFj6CCyt67iej+ZjDSJlU8po/UwVxZHVY5MUglcDnvVFcz95YrSX3bFi/yc3r1lAAAAAElFTkSuQmCC>

[image2]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIAAAAYCAYAAAC4CK7hAAADrElEQVR4Xu2WaahNURiGX/M8y5DpGstQxkTIPHTNIVMyz1MyZCplyA9DUTJEZiIhyphclCkypEjk5g/5o0iKxPve7+yz91l3n3PvPYNf963nx95r7b3WN6zvW0Cx0q4SpAc5Q16RvaRRzIz/qNJkEllNKjhjBakx2UM6kTrkNDlMqkXGa5OtpB/M6IxJPx9FTpEmzlhh1JbcJ1NJGbKQvCTtAnM6wwyUsYVSa3KALCBtyHbymfwij2Fel/eDyiLnyTCk7jEZspHcQ6xTSsEMPAmLUFxpc/LIXTKOTIR5aTOZR26TvySXdLNP8qTvlpOLpG7gfbJqCdvDMphRQcnJt8hIxHGYNjOL3CRdyHTyjoyF/0F9coP8IRvgL9KAXCdLYF5LRdXJDrKCVHTGpErkICwqmhsjbXQEeUIGkI7kNTlOqgbmlYSF9ifZD3+h/rBve0aek5UcMxmWuuVJe1IrZoY5aimssmk8RlmwfNwF2/gq8gD5D5UMHkO+wbwiQ2TcfNj8Fv7UIkv/GU62kCEkm6xDeAlW5ZKj5fyo9APl/xcyHnHyLiKNTSDfySaYB8uRnbCUrOdPzZNKsFJEi6o/yIN6vkYewcptVmSuioqqlM6gxyVSIzIelOY+I3Nh+89TZVgKfYCdjURSWBWtr/CNrkJOkMvIv2hfsoYMJZ9gG1VV03nsSt6SlSj6uWpOHsL2Ev1WoVNavIFZmkg1yQXyFH4aKRXlbfUPGeVJkZL3lSIqIjJ+Efyy3Z28R3KGNCR3YNU0WtVkiKzLhXkpnuT90bDIzYC/uDavCuIa4kmHdjfscHqOUjqoR32E5XtR5RmiTl/We6mqcIX8gG0wmnOOZOQLWKP0rg2SDvw+WA9xU0tSyVb/OQe/XHqRVclOpu8otXTGVAyijVmhUR7/hh0g95woEr1gHV2HU5sISim0DdZfwjalxqkU0v3LW7Q3LLJqotrUeoR/G09qikrv2XAc35TkwCqFKtIRMo0shnlSG9GiYRdBpZhyXx5q5YxpEVWWXFiv8d5pA/qn3s2BVU33ypNIcsRzMsgdkHR3UaNR7inNvIY4BSEd1FEf2I8HOu+Vv2vJMdiN1lMzchR21dA1JJiqBUmOmAnLEEUmrVLByIGliHs3Sre8VJYjwopLSpLnZYSaoipKJqVoXoXdMBI176SlvqKOrRKdkQVg51FlW9ejsAqZFil3dfc5hMxFpQM5i8T9Li1S5dHNVd06rMKlIhUjXe8HI3MRL1ba9A8GuJ8agwMZtAAAAABJRU5ErkJggg==>

[image3]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACEAAAAYCAYAAAB0kZQKAAACwElEQVR4Xu2WWahNURjH/2aZMkuGZAyZh/IghQwRcZU5yhQexIMhyQOhDDclL0SUyAPxQpkuKVMimXVTPHj3qMT/v7+9zt77O/uc657jSf716567vnXWWt+wvnWA//o76kuOkgne4NSVHCRTSRNnq0pa+BRZS5o5W57GkYtkrDdUKm26kZwhnZytlPSdzeQCzIEitSZ7yXfyg2xHee8GkttkBfLD24XMJp3d+FByh8xH/veiTbeSr7DclVJTsg62WL+sKVJzspPUk0nO1pachkWjo7NFakfOkfukl7OlpXlnyUnSxtkkeX+N3CU9nU2ObiGvyShnizSAPINVeytnS6sPuUd2wLz2Gk7ekFpYmr0U5XdknjdIc8kX2CHOkzrYZitJy2QaxsM8WY0kr/o7g9win8kv2EaKxmJYCoOGkRdkgxtHC1hh/iRXYd4qGofJSzI4mRptpnzXoLi4dNgD5AMZ42xBivhj5BS/8ngdlo6woQ5xDHaIQfGYNId8JLNSY0HdyM0Yfc5Tb1jd7Yc5X9BIWPgOIamHHrDwqsF0iMckbf4+/us1GhYFRbBUXYVDqIMW0qyQLoFdzQXx/9I0WH43IZu7yeQtWYhsOvR5KflGljlbWkrHE7IbqcJWBYewD0mNqbrlsdqsmssi2GGU61dkFbIbyfMjsIgqsrrKe8j01BxJDes5rNcUnFNPeEAuIQl7d1gqLsM2PQ67epIeLc3fhewVVSNS/6gj/WFtfR9pn5ojTYE5rAIvaAR5SJYjOZkWV0h1Ra/A8h8qWZvp4dI1Tm+gqMwkn2BXXQf3bVvrryFPYRGpWFpIdVLJQuHaqzP7CDVaajiPyHq4htOAlKYbyO8xjZbStQ32EPmQl5LSqQjqAfvT579BqRmdgLX1cs9+kHqICn2iN1Qr3RRdS/1qKif9iNGbpMKtOg3/rn4DnLFuftmb1pYAAAAASUVORK5CYII=>

[image4]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAXCAYAAADUUxW8AAAA5ElEQVR4Xu3Rr2tCURjG8eOP4Q/Ggqs2FQWDwyCCYHDLFpNoMoisDgxa/Av8UwSD3eKqBjUaBetkNtHve++B3XvmdWXB4AOfcp+Xy3vOUeqef08ALUyRdFd/J4s5Nsgb3dU8oYkxdqi4a+/Iuq8oYogv1OBzDnklgTdE0Mc32vA7hy7lEVU8K3v4HQf0EHTM/YoMy9kKyl5RNLBX9vqhn1F35II+kDO+l7HFBDGjsyIXVEcHD0YnTyRPNUPc6KzVShjhxegkGayxQtpZyI0ucNI+kdJdFAMscdS9/KSLsJ655/ZzBg4DH/SezhofAAAAAElFTkSuQmCC>

[image5]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAYCAYAAADzoH0MAAABKklEQVR4Xu3SvyuFURzH8Y8fxeD3glIsVouSYhBXEmbuH3Ang1HsyiKjVVkNdkQpv+50RyaFIkLZlHh/79d9nOdQlruo+6lXt87nee455zlHqqSsqcIY9vCMD9ziBMc4wx0OMIEaf+1nGrCFGwxH3QiucYn+dPWdbpzLZ+qIunbsy1c4HXVJMrjHOuqDcdviDB7k2+oJuiS1WJLPMCd/ydKKBfk3OcJg0KViD+7gDYfYwOrXmK1qBc2lh39LHy6wjZZgvBqz8uVvoi3oktiSsnjBsnw7YUof0P5kPOqKqcMaHjEZdZYu+X2w7zMVdcXYDLsooDfq7NLk8CpfRWe69gzJL49dosZgvAmL8q3Z8Q0oOoFR5PEuv75POJUv136v5Ec3rz9OoJJ/m0+/fjnJrLKoVAAAAABJRU5ErkJggg==>

[image6]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAYCAYAAAAlBadpAAABC0lEQVR4Xu3SP0tCURjH8Yc0EUVFwRcgiks4OLoIjtXQ3uKigy9AB12sJie3aHKoNaixtTbBiBqikBwcHBuCpha/j+dcuVxv1OAi+IMPF57n/Lnn3CuyzVqSxxmGmOEdT2ggjQ4Ol6NtYjjBF+5xhLjtJdDFGK8o2PoiSQzwjRbC7qZNDo+4FTN+kRDaYiaeiv9EjU64FvPau06xjClGyDpFn0TRRMkpRHCOHzG7L1f8T/Qcz/jEvqf3Z4r4wBv2PD13gjgQzy1nxJxVF9CFfot++wvx3InebF/MTdcQcDdt9GiXOBafvu5+h4mYH8MZoE991StUsGPrK9G/q44HvOAGPVSRco3bZvMyB882J9fBLwMJAAAAAElFTkSuQmCC>

[image7]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADMAAAAXCAYAAACmnHcKAAADtElEQVR4Xu2WWcgVZRzGH1NzyS2XcklUhBRNzbRCCBUrvUgjBesiTVxQFEQvREzUNHEjUltAUgtyN3fRCxXJBcJUCBdCgzLQpCvvFCTCnt/3n/GbM9/3nTPQjRfngR+cM/POvO9/H6mqqoqog/nYbDfjzNOlt2vUxEww75vGuXs1amSGm93mtDlq5pu22UXWs2axOWVOmO/M64rni4oDdFEcKivevdmsMC+ZnWab6at4P+uHmK/NOdMvHqsrFuGN1xQPdjK7zFemVbKmhVmqMKZ1sg4P/WxGJGvKqb0ZrTjkBfNi6W29ZS6aYYp3Exmcu8EcUuyDEb+YqWogKoRyuSK8WW+9ac6bV5L/g8xBhadSYdRWs840y1zPa4z5VRHNW+aaSo15yswxV82A5NpAxXvT7MBAzrRaEcV6hee/VUQmu+hVc0aRRmiUuWLeUW1aNTefm/XJ70riYDgkbwxenpdczxqzyrRJ/vdUpDXnalBEZo15ZA6YHqapWaDYuHOyjsj8Zv42HymiyIGon0kK71ZSQ8agsYoUStMMpy1SRJwUX2bmKs5WViPNHYVBhHqTOW5ezqwhghQoax4oipM1bMhmRVTOGOr0B/OJ6W4+UzQlnET9kD3PP15dRnj5A3NXcdh/zBeqm5vdFEXJGrihSL+i3aycMYhr35uTZrziXOzJNeql0D6k0kZF59in2sNS3O2SNeT1uwrv0T7TSN42b6vYRpWMyYs9ZyiaE+mGcaTj3uRa3tk1hUvNkEIUGw+8Z26a+2a6ItRDzY+KFoq6mm/MQ3M2+V9JWWP65O7Vp/6K8dBLcYYPFW2aDjvTLFSui3LjJ5V2KfSG+cN8qTjEWrNDtZFCzyiGGO027XrllBpzXZWNoUZXKhzLuaipI4qaogngPLpo7/QBNFoxxBicWTFDyFWMeS75TVHm5wkpdknRhSqpqDEcnvdy8HRoEyVGA12W9MORdLgSJw42l81klbbXjmaPmaboVkTmmGpbNWJTvpEOKwoVYfgU1V8TRY15QeE4DEjF3GHwljWGmmE4/W5mJYs40BKzRfEdhYgcntmv+HZiPo1UNIyJig2oNzb4N1mXDrxUfNLgEOZVtu1nxXsZoDg3+8nCOZhpy1UmzVBLhSF/mr8UG1Js+fmBpzg8jYFo0v2yHiayDNB7is+O9KsA4/mUYT6lnZJ30Dj41MnWKt+H1Eq+U2HYbIVBvI/BXacBPEnCgE8VBtUnsoY0I91Iw7zBT5SIEAcuMrOqqqqq/6n/AMcQrgqrb3Y8AAAAAElFTkSuQmCC>

[image8]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAXCAYAAABwOa1vAAADTUlEQVR4Xu2W6auNURTGH/M8ZVbmzGPGKMkUmYciCveDMs9RJB98IBlKMifXTMhcCvmCDJlJyJB5ypiEDzzPWe8+7z77nuPeP+A89et23neffdZe69lrXSCrrNKqCBlIrpPf5BaZSEr7i6jqZB35TD6RXaSV9177TCcrSFnveUFVkSwnj8k7coA0T1lBFSYjyXkynLQh+2GBLybFo3UKdg/ZQJqRHPKa3CYtozUlyEryNwNvSI9obajysGQcJ3VJFbKWHCE1vXWoBgtkDCx4qREs209JZ1KIjCZ7YYFLRcl82MHWkFKkHNmNvIE6VBFlMZQqM5l8JXOiz1I7co9M856hNXlEriHOlKywmfwis2DBLCM/ySLEWe9GXpGrpB7s8JtIp+i9k6qmgyiAdCpDtpEfZBwsQVJ92N4H4R20Mays8kzP6JlKu5r8IQtIyeivPm9H7M/25Ans+6qKSjeFVI7eSzXIDjIeVpV0UmX2ke+wSruA65DL5CZpGD1L2EA/rGy5DXWaQ+QbzAraoBIZgFQ/DYJdwFOkqvfcqRiZDatOeIF96d0WWIbHIg7YJVNJyVSdhBT8c3IageE9qYzrYYfKQex/X21he3QPXwTSd+Vh7TUTsV/7kg/kJekaPcsj3dZccp90SX2VlDLQh7yAdQUFH0q2Wgq70OkuWih1ha3kMKkNs5Js+ZE8Ix2TKz3JEvKgglX5XWlC6TKchfnZ96sveU7+U9DukuYneXkuuQDztOx4BdYpmnrrElJwunTnSH+kL7GkCqg/boRlJZ201wjylkxA5r3yUxNyF2Yr106Tkt9Own5IP+DKPgSxp9TeFsIy6zZQhqeSWtFnSRnVxFJfHeY9/59kg1WwLuEuvxIo/+o3dYGTUks6QSZ5L/R3HhkFC16fZ5CjpEG0RmoBGxzqwU4VYL1THUTWCqWDa6rqcrvs64LJr8dgntehl8AsocmalNpVLqwHqknfgA0DTbD3pDcs4H7Rc815efMB+QKbYDth/nNS8GdgASiQUINh370Da12SDn4JNtV0oKHkIqzCKZZSD9YIDseo0ATUlHKDJHzvUPn9i6Wuob6q8e6mp68O5CGsqq4yCqoXbHwrcP3j4/4tyCqrrLIqoP4Bpd+uoVfQjPMAAAAASUVORK5CYII=>

[image9]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAXCAYAAABu8J3cAAAChUlEQVR4Xu2VWahNURzGP/PsZp6SSDchFCFKpiRRHhQuRVLiBSlSUl5kDslQiqIU4gkZ4kFRIjzIlCHJUCIPCInvu99ad6+z7TrnevJwvvp19vnv/97rv/7D2kBV/7mak3nkDrlLLpB1pGfqlFNrspkcIu1y94o0kJwkr8hbso10Sx2akOnkOOzclMwnn8kxUpO5lmgC/FL5tM/dy2sAuUR2ko5kEDlPtpA20UkX+8lXspw0C44PyDMyMjom6gzv7jfKB6JsHSTvydRg0+YXkCdkUrDVp1iRKQNL4UAGk0fkBf4ORBmbS06hsoz0I7fgd41K7FPIG7KBtIhGXaheWkSaQT6Qc6R7dArqC++wDs5auUBU7vtwdkck9olwr5wgHRJ7g7SDs+Q6GZK7p6ZW+VaTYagsEAV+kzxHaXa12Y/kMnKbVROtJ4/hlM2BF06lwA6Q/sj6qFwgbeHJekcmB5veu5b8gDfcJ9hLJKdl8INrSMtgVy+pngvhElYaiKQNXCVb4TIom6fJN3KN9MhcS9UVPkuUmdjpGtfd4Z7UmEAklWgPXKZ9ZDHcI2cQjgiNklLTO1xLSudheDx3wBFvJ9MSn8YGktdM8onsIq1kGEtews00Ojhp9o/Cgewlw+FF9b+I72QlPPpFGgOfVePgjchvFZyRWcHWMEZPkc25Rvki+UKWIBvrVHp50TmiCVhEasN/LarG/Ek2wT3YBS6JRrdT8Ku/OAKfDXJQU6pJFYQaKn+ORI0nr+FPQzwHtMhG8gt+VpOo3c4m9+Cpka8Cu0KG+rFM6gGVIGbmBlmB4u9MLzgLCjSW5iGycddU6XzQB1GbkvSrzOp8ug03rc6rqqqq6p/1B+BNhm1OnQAdAAAAAElFTkSuQmCC>

[image10]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFIAAAAXCAYAAACYuRhEAAAE6UlEQVR4Xu2YdahlVRTGP7u7UOzuBhUDTMZuRVF8DthgKxiIf5goBnYgV+wEMcECC2NUFEXFGLALFUVFRfT7uc7yxD137n0PZhA5H/wY3j2199rfWnvtkTp16vQ/1ixmF/Oa+d28YY4wc1dvspYwV5nvzXfmVrNO7Y5+bWieNts0L0xnzWVOMB+bX8yTZpJirlWtax42vyruvUAxz0Ga05xnrjPzVC/MbPYzz5m9zHrmLkVAzzKzF/fx8tvNNWYNM2Y+N2+atYt7muJDV5uvzLaNa9NTTPZsRYA2VSziFPOt2dPMVNy3gWKRTzarmnMUQb/XLFrc09RWioDfYuatXlhcEaADFUFFqyjcOdVsovjwAeYOlas1qzlVEfDLFQ6oimd2M9+YrzVjA0kWPGQ2Lv5mLLiRcTxlljRzKAIHBB4tYG4zP5vJKuORWtjcbf5SSyCx9vvmVZXOIqWvN7+Z4xVBOl9h/zNVunRL85l5xSxf/JYi4LzjMfOlZlwgCRoZ9qO50yxS/L60eUGRHTiU3x81X5g9FM8RuKMU87xZ9UBxbX9zjwY4EkuTnvkBxGpdYv4wpylWjH/5u/qBjcxHiudxcYo6dKgivagnDHZYIJkIY1m5eaGiZcz66ndKUzsranh1gcm8J4rfd1K4D3elWRgzYzhI4UjK2/z/PBni29cqMvdttQSSQREQ3EW6ogXNfYpVJaX5wEKKAZIWqV0VGw+uW6zy+0qKj+J26uwogUTUrJtUpmRVqysctqPKGjdIGAFTrKXy3tXMW4rsYzHQCor3ZUBmU2QchrlQ8R5EXHAqmxdzag1kmwgq9n1c9cBVlRsJwR5T6RLSnuJ9uMLJ4wkk2kIRzKrDKRNXmn013I1twm10ITiNTGvW8xSue8Z8oNgbUiwImyyBZ0FHCiR27pl3zGb1S/+KVd7efGIuVr0NwE20SEspVnK8gSRQOL2ncDa752WKhcExExHveVFRE6mVbWKsOI56PqayTcIMuJSUZ2wjBZKXHa0IImk8KIVYGfoy6mUWc8SLz1XZYkwkkIgBswFQXkhn0mqiQZxPkTnPmjUb11KMdWtFgOhEMqUR7Q4Lme3Q0EDyMuoKfRXFeFAK4dgrFDWw2mvx/A7mIkUhRxMNJKKk3G+e1+AADFMag35yWu9Y0TxoTlQ9iOwVzId5pamGBpICzAf3VgQx03d3lTantpyucGL2kzjyGLOsImh/KvqsNl42y8Vj0xQ7LCcH3IG7e6rXzFHEHJjLIyo3F4J0iGJzTTGPniJ9s5/kwHGY4jmC1pxHwo5/nCqnJQZJA3ukyhTi31MUvRNB5e9jzQOKFUxRiGnImXxTDAz3judkgwtIRXZNVjxr5o0abRFQmoDyQ8qmm2io2Wxo2FF+i/Fnq8O9HCTOUN2dKTYhNuI+R9LW9MxPir7rdUWTzYmFk8B2ipdPKn7/0Lxk3jM/qOzyqUVN4WB2O95DegwTE7tU4UbGlWLFacNu0GjBpNVhc2EBGSttD2MgWzh4YITsLpg3ffAURU/MEZG5n6T+czna3Hyq+H+G2pyx+VT12xbouTh7Z4PevJ7gnjztIFyEk9+t3EPrUS0JTfHMZIU72s65TIpmmINBm1NSLPrBiu81xwn0vLyfDMKxzetAcDMTU9RsDFN9L5vyPhq8n3Tq1KlTp06d/nP6G5LzF1+4pmkdAAAAAElFTkSuQmCC>

[image11]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAF8AAAAYCAYAAACcESEhAAAEi0lEQVR4Xu2YZ4hdRRiGXzWWJNhNsYO9xWBLLNjFCip2E8u6CVZMohF7b4kFK/YCVhIRRNSQoJgNBAvGAtEkYISAEZLf4g8RwffhO+Odc++y9yzsgsK88MC9w7kzc7752lyp6H+rTc2lZrn5xTxpXjc/mRfM2Najg9KW5jrziXnTPGcuNLPMLtlzTXSI+dz8bVaYm83RZrH5qxq71WyWftBF25uXzZ9miTnJHGmWmj/Mq2YPs7/pM2sV74KthlwY6l3zqFoL7Gm+NjPNRtVYUx1kPjVzzHbV2LbmfcU6W1RjTbWBOdd8Zw7Nxs6sxiZVY4MRhl1mpijm2tD0mm/NvtUzI8w55rDq+7BoN8UJX6LYCDpAsblrFMYfp9gwm0zi2f3M+GxsH/OZucFsko0zx9UKD+LzaHOwOr1pZ8XBp32gjc2dZpFaa2GY26oxPDmp6by7Kzz9SsU7bWWeMisVkZaeOV+dc9V0o/lRER5fmV/N72aNIiz5jlezeH8i7L5Uy6vw1ofNXEVUoG3M3QpvY7O8xDGKFIBXI8L+cbNQdYMgfkOq4LAQBzPNzDAjqzFCHSPvXX1PwjDzzTNqPbu5ecs8nY2hpvPupIjO2YrDPdxcb75XvBfzX252TT8YSAeqZYibzFHVOAs/YS4275jTVfcqvJAN/Kw4+UcUnnuPYgO5Rik2RH6cbHoUnpZEBJGq7lW8UDex9imK0MbLrlXnoSHSwA9mgcIpHlLUkNWK/eTvg5rMi4N9rNjrjuYMc4IijWGj481ZaphyJyjCcIwiEgg9RHheYY6txu5TPefyGQ/C8Klg7aB40WcVBs9FJDDH/dXnXEcowpYC3m4QnsWIedpCHBL7e0lhqHYxz9kK4+OdSUTrF2pFa7u6zct+iCbe+0SFh+PA5PyrzGVm63+f7iJydG58ih7iZSkqnCanT/jlXsDG8tyHOJB55gN1boDiw4aJJrw/FynlG0XY50bm82kKz2o/FLyOwkyXdYHCWXJhRNId0YhToBStOAi1qD91m5eIfc18qNgXc6YmgwzR/m4DimJIu4Xx2VgyPpP2KBZg7C7V0wkexILJqzAOnrBKUWzTphkncvAKUhs1gOKJ5yWDEjnUFjqa1OWwPvP1qp6bEQZijr0URY3USE3JDYWH4gj95Xsis31O1GRe9ooTfaTWAdIC44jPq55Ouwqvw/j05bnxycMvKqKCVu9khbFYHG8nnNcpFqS/pwgBG867FboFuqE8ZVEIp6telDAML/6Gecw8aC5SZw/Oc1NV/y3r0V2QvtjjRPO2onkgF5+n6EQwPGMUR57PjdpkXkREkSF4zxSl2I4DZY1BCePfovB8CtJ7Co/pM79Vn1N4FQ2xcuPj+acqOhcMjgfiRUXDJHJ+bnzyMymGHE/L9IAiTRQNg+h22gsuReN2xdWcnM8Ns0n/XTRI0efnnp8KLrc60g/dDEWVC1LREIsLAjdb2kCMny4fVHIqOtft48wriigpGiLxt0L6b4eene6Gm+Ydij6YixI3PS5A6xU9fH5bLCoqKioqKioqKir6b+kf6S3BLjZujqIAAAAASUVORK5CYII=>

[image12]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACYAAAAUCAYAAADhj08IAAABq0lEQVR4Xu3VyyuEYRTH8eN+zSV3koVLYkMkCwsLC5SiKCwlYqvIf0AplyQiFAsLl5VkLXayUiSXFRY2Fmz5ns5M75hmDDMaJb/61PS+77yO85znGZH//LFEoxunOMMBxpDr+VC4E4FmbKIEkejBMzaQ6jwa3iRgAa8YQhTKcY5r1DiPhjfxmBDrUL9YYRW4wK38YmGaGGSJLaOmFU/YR7b7IR/RMSgTGwF/KUSVOO8OOkXYwxEqve75SjVWUet9Q2wkttAi9k8ElRSM4xL36BTbrV9Jg1hxpR7XcjCPLvmBbmm0mEE8YgSxH2/7jP7hNqyjGJmYwYDYmPxY9MV6lmnnmrzu+YsW144dseXTHR5SUbr2Bch3fdYkYgVvmEKc63qg5GEXx2I7O6TU4w43qHNdSxJbFi1sTuxICRTdvUsYRYfY9z1n7ttpxAOuxNlZenQc4gV9Enh408QO6UkkizNz2nXd5UElHWtYRIZYd3Totaht+fwc02hR02Ld0ne5owe1/rQtSwjF6dbWJXN37gTDEvh3UjujHZ0V2zDe0eJ6xY6hr87pf/5W3gFjqT5sbHRpUQAAAABJRU5ErkJggg==>

[image13]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAUCAYAAAC07qxWAAAArklEQVR4Xu3RPQ4BURSG4UsIjZ9KSNSK0dmA2AAtvYhCJdRUU4lEoaLQKXS2YSFqhSh5T+6Ee06iU3qTJ5nJdzOZyTj375fVscMdV4yQT7YSYrmo4oxncuiBGwZIo4O1HByjIRdBcn9A1/lDNbUGFbDCFkNk9PwpiwUuaJlNJU+YY4+i2VRycIK+8x/0tTI2aNvB1sQJkR3CUujhiIrZVPJ+UyyR05NOxpnzf+TdCyyBFUzJX7iCAAAAAElFTkSuQmCC>

[image14]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAWCAYAAAD5Jg1dAAABGklEQVR4Xs3SvyuFYRjG8cvPIyGD0jEoZaDMslktpM6gMKBMomTwqywiFv+Av8FEGZQsDAabslnIX2D3vd/7fl7PGc7J6KrP8F7v03me+3mP9O/SjyPc4xkX9a89fTjAPNri+bJuBWnHGtbREV0nzsoVkTH5NkNZN4Dr7LnYZgXLaI2uRX6Ep3gu0otDzOEK3/jCW3RlRnCMYczIB9qT/5rdQJnpeNGVdTacdQ9Z97eFNsgqFvU7SOq38JqKbuxjKhURu8NzZQurOJUPkmcQd7hNxSRuMJ4K+bb2lT6wZIVd6gJe5Ndgx+jBBt6xqxiwgm3Mys/5iE/5lvZVbPIi9i1PMJqKRpmQL7T/YNPYljvyq2iaTdTkQzXMD7PgKFIs6ZWBAAAAAElFTkSuQmCC>

[image15]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAVCAYAAAB/sn/zAAAA7UlEQVR4Xu3Qr2tCURjG8deJDEQF22BiNMiKFsPyYFnBvmAxiBgMphumRbQIIizNLRmGbRatYlUWtiCGwcQ/Ycnvu/MKcsFm3AOfcJ9zzj0/RP5z7kTQRQdh60Ko4uUwSZPGCm1cWneFGUaHSQHk8YMHXFifxRc8+/7b4hEb3Fqniwv4RtE6iWOMOZLW6WIPn8hYJyks8SzuUhpd/IYpEtbJHXZoivuT5gYf6COnRRA1/OJJ3NPE0LOuhbJO1K2G2GKCd7yKu0gFCwx0oh5eL6GDUS1ORZ9jjbq4Y5xMSdxb3fsH/GmIO9u1f+A4e1mHJh0i99nEAAAAAElFTkSuQmCC>

[image16]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAAVCAYAAACg/AXsAAABLUlEQVR4Xu3SIUhDURTG8aMiIsPJxGDdwoJha2JxS6JJGQwMsrQwBYsGTWIRm0lnE8GoYFEwiMUmC7owNBlETTbBqv/jucJ7D93uSxY/+MHePfe9e+69E/mjpLGLG5xiLFzunAQ2UXa/13EVmuGRIRxhG/0o4j40I2a6xDq6ixbiZBCH2I8WfNOLRexgJFLzim5jAiti3WSCRT3tBbTw8QM9UH0pJ3awJUxiVV/WJFHHG85xhne8Yg8bYqsP41jCH/+6nR7U3MO0WLvdqOIRUzqpU3RP12Kd6N1/ZwZPmBP7cNvM4kVsZe1Ao90tu3GvTpbwgEJgLIUTNJENjP+aCm6Rd8/auq7+jC30ufG20ZUuMC+2nVFc4kDsNryiK4+LXV1D7H+yhoHgpP/Eyye4iTSfp+OO1QAAAABJRU5ErkJggg==>

[image17]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAWCAYAAAD5Jg1dAAAA9klEQVR4XuXRvUqCYRjG8VvNBIfIRegAcgoNGsKhRXIJIVBQ8gR0dHFo8RA8ACenwMGtJocWt1DJpcEhEBpq1Mkc6n/xPJZle4MX/Hjhfu/n2+zfE0IOQ7zjERVE15uCKKKPPFLomBvQwO6qMY4blM0NUg7Nzf6MU1+zJCYY4MjXtGQLC9TMbc0SGOMVGd8YQRNLXGNHRS13grNVgeyjixmuEPD1jWjQFD0c/Pr3lT208YT0z18uml57vMeFfd/ARo5xh4K5Jg3M4tL8qRXd2y2qCPuavnWUzB8mZm5PczxghBdzL/OGczUpuhq9wMcf9BB60i3NJ56DK0v3veByAAAAAElFTkSuQmCC>

[image18]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAWCAYAAAD5Jg1dAAAAaklEQVR4XmNgGFSAA4jFgZgRXQIEmIBYBoijgHgfEC8DYj4UFUDAAsSlQHwDiLcD8QcgXsOARSEy0ADiqwzDTOFaIOZHk0MB1FeoA8Q3GSABL4omB45TXyA+D8S/gfg/FL9igJgMsmWEAgAn8RshGbQEiAAAAABJRU5ErkJggg==>

[image19]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAAYCAYAAACvKj4oAAAEE0lEQVR4Xu2YaaxdUxiGX7Rqbs3EVKpCiTkioSWGagUtNTdSY9AWEUMIibQlElNCglY6kBpLEBKzKBJFzBFENO6vhqaJhIggwvvc76xz1t7n7HOvc++590/f5PnRs9Zea33rm9attF7Drg3MUeYZ87V52OxWmDGEGmHONzeZTUtjnWp386A51OxgnjLLzOja+HbmTnOc4jK6Jhafbp40e5TGBqL9zQdmlhlp5pivzAHZnMMUhnMJ/dJ+5hEz20ww95ifzF/mY4WX8FauseZ5c4q6d5MYON+8r+IlbqQw/AmFRyvFobmp98xZ5jzF7d1urjDvmH9NjzkyPukV311nXjQ7Zr8nYfBk85ZZq1jjbbNTNmcXxQX9XRtfZ+4wm2VzxivOdq3C2Fw4hTWnqeKCOeSl5k1zuLnI/GDOVOODnc0b5h9zmxqbcLjXzdWK26zSNmaF+cP8Ys5Q8TCc4UbzkBo5ljTG3GuuV9HopM3NYoUXmVsQm5xmPjEnmEPMt2a52Sqbt6EiFDjgIjU2Ol7x7dG1f1fpQMWadyvWeM5snY1TmPDaDBUN5yJnKlJjE3OQ2TYbR1zsNYpKy3hBYxVxfb/CIG5xlZqTlk3Z/FfFbWEgRl+pmL93Y2qT+PZsRcXjAJ8pwvXEbA6RsFDFAsL6pyoMn2JONreodaugkuIYnFUXC5BfbHaOKuK3JsbONb+ZBYqbHWXuU4R2nlNlMW+euVDhBQ5JvtECUiRMMg+o6FWKHFWTvEy8VJqTxNzPzeUKu3q1hSJsflTkXjsRBniX/EmXsaV53Lys1psmYTyVOe1BuH5jvlekBGtTtSlW5QLSX40zHyrOWK8FuJrw+k5xA+1EkXjBfKpGOBLSvDLofxhbJaou4bd97d94kfaDF29V5BSRcFJtvBPtat5VVP36JWEgVveYI9KPLYS3Tld4+mI1bgijqFztDCRc+OZms3H2O0azHiHII2Gp2Ssb/79KBpLn9X24uVfM74pD1GO3JIz/UhFmeQknf/AMPbAqRCnhd6m5R/E769F2UpEjZToVIfqRIr/rDxFcyc0SKiRoOQ850ETFC4aCQJjmonhQ9umPrZo82tMsMfuWBxRt6Wfzp/ruo32JZk/6XKaSozjASkWFokI+qqh2Vyl61WpF8rd6QHOguYqb26c0hhinfz2r1lWWpvy0WaOoogPRMeYLxaupSbzhaJTEMOGaGv0FavEyKOlYxcJ5T8PzUxWNN5X3HkVPy8M05TbFiz7YqfDYJYpIw5ODKgrVSkU17LTED1QpVR5TdbHrWFQsjKPZU8mGQ1TfV9X8zBs00RdfU4RbVzZoo/RI4PlYVckHLHKANyDVcqi9eLDir5R2fXxQlP7L4ga1rrjdEMWRP6N4AQ115KxX1/UfIH+zfm5rSYoAAAAASUVORK5CYII=>

[image20]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGoAAAAYCAYAAAASy2hdAAAEN0lEQVR4Xu2YaegVVRjGH8v2orIyozKyyGhFjfYi29wwrbC9iCQJAxOK9g9FRbvtC1l9MIPSFlqooIKiiOhDgYRCaka4tGEbFRFRz493hpl7/vd654Z6Cc4DP/5637nnnnnXMyNlZWVlZWVlZa0nDTKnmnfMd+Yf864ZVrtmd/OS+auw/2BuM1vXrtlY2tHcZ75U7AW+MU8q9nmJ+cT8Wdh+VtzPsXx5A+sohR//UPw2f59V7Asff6hqX2vNHLO92U6x/78L27dmhtlUbTTELFAs/qM5QxHEUoPN1eZRxeL91iTFzT5ltklse5iPzBJzUGLb0MI3JDVJf1JiI2AEa4U5LLFtZW5V+HidBXCIecbcrQjWC4rsLcVCVNGZag1gP0TSXGt+NdPNJq1mnaxwFA6r30Mn7WpGq0MGK5xPtWyZGtqIpHna/GROS2wjzWdmtTk+sR1hblcUTEfh+LMUFx5qPlXc6Cm1a8iGx7XxM7SddlAk0nIzJrFtZm5UtJjrFEHtJtr8A+ZsDQwWgX7IzDJbJLZ24hpa82/mAlVJvbmZZt5XdIKJxeeI+6Gajql91lYsfrO5WJE1Nyjm0SOqypAMeFDNMvRI87WqGdINKuN8Na/UAxVt7U2zc2IjI18x3yvmQlPtZeYqqrHcB764xlyv6ChNRGLcpOhKM1VV+77mOPOY4n5JCn4H+znmSjVIBDLqCVV9kza42HxhRimyjB9lMTK2n+LmzjW/aGDA69AV9im+01R0C9r/WEVgZps71dtMxlf4iUDRngnctuZERVLRtX43lyqCRDvkULE3X+4mKoC2tkvxfzLpHkVV0UZ2Uiw2rrD3U+yNvRCoMitL1YOIw3FQr6L1P2/mKXxAW+pFOJ8gEAyCQpXgX7oAQaMdE8SrFN3pDjWc+yzMkZYF6KOlWHyFWWSmKgbkiJq9X9rNvGeWKpxaF065VzGfqIZ03jRReWiim0xWAwcmKuc97Y3RQVUz6/Etvr5cEahbiuv4LY7nXcUp5S4zRa2b4nPaIWf7DxTDtmmG9jqjqAAqoYlTjjYrzRuKSq+rDOIac0KLpZnKmUR3YSZTVRyxm+yrrvGKZ00qk8ccDmKIdS5SHDReVPj34MLWVfRGnkX2Tw2KwcrDFxnKqee/ZOj6FBnJgyBthYxM5yWnJoL4sRme2LqJta5QPEvuWXzGzCJYHAJ6CRYP16sUVUmg6n6jO/EQTnJeltg6iovOMwvV+iaiFP35ObU/9/dDVDSO40ZpG3XnEcTpiiA+rOanNESQcNrrGpiwh5v5iiRoGixa8jLzqqq5X4pDBcn/WhtbW00wn6tqP19pYE/m36ebl1WVbz/E0OXRgDcm5X45lfKWhHZ3oWJmlTZeKb2laJNNRBB41XNAaijEw+j9Zmhq6KD9FI8OHL7S4BL4t4u/WVlZWVlZWVlZWVn/H/0LDi7fnPrFt3MAAAAASUVORK5CYII=>

[image21]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAC8AAAAXCAYAAACbDhZsAAADI0lEQVR4Xu2XWahNYRTH/+Z5npJw6Ua6mccoY2YSmaduktJNhAeSIa7Eg1J4UJ4MCVFCERHlRQjJGA/miLzywP/fOsdZe++zb9++6ib516/uWeu0739/37fW+g7wX3+P2pKV5AQ5SXpH0zWiLuQg2UfmkVbRdHHJ+BnyklSQzqSWyzeFvdgVcg/2gn1cPqv07PakcTxBtSSTyG1ynZT4ZDFplZ+RvaRBLKfPW2EPKiNNSCV5QAYVvhYkmR1C9pDHZEo0/Vu1yQrygUyP5RLqR56TXaReLDeMPCLLYQ+VupNbZDOS309TKblJbpA75CuZGvlGQdqZcpj5mdFUUgPIC9iKejN1yBryjkx08TbkIjlHWrt4iOqSLeQzqja/BGZ+ViyXkLZf530H7OF5NSIHYOZHunhzcoo8RfazH2p+Ecz87NznVA0lr5A0L5PqPG/ICBdvRo6Tj2Sci4co1PxCmPk5uc+pGkveko2ImlflX4CZH+7i6j5HyCcywcVDFGJeUjG/JstQqLWEesAMPiSDYzlv3q+8Nz/exUMUal67q35/lfRHbPXV8tQav5NLpKdP5qRjcxpJ83rwMVgtjHLxEHnz02K5uLrBZstPWI118En1cLXC87Ah1dUnUSjY92S0i7eAvZRmQ9ZJnDf/BVWb13Q9ChuKk2ELlpC2Q9sng2th7TEv/b0OVph+izWRL8MGV0cXD1GoeU1Z1eFqRD0lpNVXt9mOaMHmc5qGFSgUTi9yl2wj9XMxHTGZKcl9TpM3nzY9M3WbgbAhFW+Vko6W4ircTrC8BpfqRGdS0sqsh9WPzqYKPU0agpXkG5mP4sYy9fn8hC1mXtILLID1dpnbDbsi5KUd0T+TIZ3RUpfLS0ftEGzFVYDiB7lPVqGwg5LMLkbghFUrkvmdCL+rFFM72NEricWzSuaXIvBu4y9mfgWyqi/ZhJTOkEEyXw5rIjOiqaTKyBOyH9Yeq6OGZAPseKVOxEDp6KrLyby6TpVSpzgMG8dzUb3V15DTHfxPV10vPgZ26dOtNTKY0qQfCiq6a7Bd8LfImpKM6ofKWVgRq4b+Lf0Cpy2XZQCzsDwAAAAASUVORK5CYII=>

[image22]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAAYCAYAAAD3Va0xAAABN0lEQVR4Xu3SvytHURjH8cfvn4WvlDIxGUTKYDJ9kUF+lcEko8GilFgMUkhRvkmxWIT4B5jsBslgYVKkjJLE++k5X85x7m65n3rVvec5nfucc49Imn9JAfpwjmd84QKN3pwmnOLD1V+wjEpvzk8yOMIbXjEq9pF8ijGHHGq88SjtOMCa2GInqPPqFWJdjEn4gSBaGMcKOnAlts1eb45ubwdt3liUMixhEuVYEDuPbfk9hx5sSdhlFD3YXXS5d93mLe7QiSJMYxYlbk5iusXabnDv2tW6WFeLqMcG+l09MYWYwjxKvXFd/B7XGMY+Wrx6lCqsYkjCv6Hjut1PXGIT1V49SjP20Pq3QLJ4wjtmxM4qMVqYwLGENzmfWhziUeyvJWYAN2JXXj1gUMLt6fMIzsTuUZo0fr4Bn8UzKE13qcUAAAAASUVORK5CYII=>

[image23]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACUAAAAYCAYAAAB9ejRwAAACp0lEQVR4Xu2VS6hNURjHP++3651XeVwh5D1QSpG3xEWUkpuSMlBSIhIDEVIUSTExEWLiNcBEiTwGkgEDMlAkSiFJ/H99a5279r57n5HrnsH9169z9rfWXmuv77XM2lQ7miW2ii75gdZSJ7FDNIr2wdZNbBfvxHdxVywWHcJ4i2uoOCUmheeuYr+4Ye7BeeKJ+CQaRLswryIMC8Ud8VH8MT/F4GTOMHFV/ArjLHZQdE/mRLHeMnFY9Ai26eK6mJnMwUvsd08MCfZm6icuiR/ii1hl2RN0FDvFaVGX2PPCK/vEGvP3Ya34Ki6K/mHecPFAfDD3XKEmiwviqPmHXRF9k3FyAu+stgJ3JxohzoixiQ3PfRaPxchgG2QeHexLgy2jeJpDYop4Zu7aBckcQshmMU+KFEPHOjF0iArEGxPDHDROvBCvxdRgy4iXDphXC+7fY54/JGvMmznipGW9l1cM3Tqr7k0qbov4Jo6bR6GZSOqz1pSIhPKleCWmmS9Cz6HMKfcyjTFfh99qqhcPxS3z3CoUZUpoBoZnTnzM3Ft7zZOTEy0K40WiH6039xTvl6mXebHcFxNyYxWx2CaxW3RO7HzoG/FcrBTnxehkPC824yDVPpwKxuP0q9IPQiTkEbHCsnmAnVD8Nj/VCdEzGc+LkONtGmeRODyVe9OaEptc3ihmxElRo8Q5MT4/IM037yM/xTYrvxLYsFHssqy3ozgslUxTnhueEb2RtKC5VsQm5MFly3bwqD7mDe+9efWVqbf54hyiSJQ/ic0BH5m3AloOUXhqSVosCYNcG/BWLLdsCPnP3XTNvE+ViQoldEXXBWtsMC//uFfKbTGgMvsfKfYcwksi14QIMaGbnR9oTVE5VCZ3WU2I0G02D19ZZf530be4JzMl3aaW1l8j/nDzbQVK2AAAAABJRU5ErkJggg==>

[image24]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAYCAYAAAAs7gcTAAAAs0lEQVR4Xu3QoQ+BQRjH8WdjE0wSBJtN0Zh/wVsE1caYYpJMILC92aaoCApVtYkmKYKimaqqvo97JnijIry/7XO7u+du9+xEwvxtYujgiAuWaGKNDaqI6kEd2ugjgSKuOKCMnUnp4Qx8pHVBPNwxRA5TVBCx+ie60cMNpa9aINrGSlwL+mIgSQzQQAFnLBAX91IdLZtLDQ+M7dITE3E/lMdMXO/vZDHHCVt0sbf5yOphfssL/tQcekqaOG8AAAAASUVORK5CYII=>

[image25]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAYCAYAAADDLGwtAAAAoUlEQVR4XmNgGAUDBoSAeBIQfwfiVUAsDsS2QFwJxDwwRZxA3AnEx4B4HhBvB+K9QLwRiNVgikCAiQFiIguUr8wA0WgEV4EGQAqdGSCKNNHk4IAdiPOBeDoQy6LJwQE3A8TRrUDMBxUDubsYiL2AmBEkwAbE5UB8DYj3AfFyBojV64B4IRCLgrUBgR0QN0IFdIF4ExB/AOJmIBaGKRoFeAEAEqYUNQkSny4AAAAASUVORK5CYII=>

[image26]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAUCAYAAAC9BQwsAAAA+UlEQVR4XuXSvWoCURCG4Qn4i1oKXkCihYIBk8Z0NpJb8BLSaROSJp1YCGKRysbCH5ILkVQWkiKYFMEUQaxyAWLe8ezierIKKcUPHlhmzu7snrMix50kerhDyOrtzAkq+MErctvt3UmhjwmWaCCytcInAdygiTK+8IkrzxrfnOIJRcTwiBVasmeqTquiLptF+oAZ3nHh1P4kjSEKnloUbTFTO4h7eusEUcMDwlbvEh/4RsnqSUbMueXthpgH6c7qDneRcBt6wLe4d679co43LHDtFvWAB8i6BZ/oVN00nfqsBf02/a30/V8w2mMqZpPmeuMZxk7hPw4lv7LvN58YzgxzAAAAAElFTkSuQmCC>

[image27]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAC8AAAAVCAYAAADWxrdnAAABTklEQVR4Xu3VvyuFURzH8Y+fCSWDklIUJkZlNVAIm5JJsimb3ab8AQaTTcogkwwsFjGYjEpJMvgVysL72/dc93EX9xlw1PnUq9s95+ne8+P7nCOlpKT8y1RgGId4wTvecIzx0F+H1dBnbsP3BkWSJmzJB2aTyaYKk9gOnzVfu/8+3TjDKToz7TapRczKdyC6WGlYidxhA42hvQsrGEN1aIsuVgbLeMUCauUDXpNPIG8GcKniO/KdJ8zIFzF3WrCHK4zIJ/KIc/Rlnosy/bjAjbxsRuWrbqfOkiIumUrMyY/JffTIt28Q1zhC++fTkaUe6/IymVax7uyU2cQz5uXHZbnJW/Ol/1127Fg8kdd3b6bdfmgK9zhAW6YvmgzJL6YdNJf0tcoH/iCfSO6V+alMyC+lwtbZGW8DtRvU3gM7InflL21ha+0G7lBKSsqv5gOOElE5aX28zAAAAABJRU5ErkJggg==>

[image28]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAAVCAYAAAATtC32AAAC70lEQVR4Xu2WWagPYRjGH/seki0iO5FdRCSSKNlurDci5QqJLCVElMgFFxTnwu5CLsiNC0uWQrYL2bMkkVBSJJ7H8/+fM/M1M/0X50Sdp35NzTvzzfu92zdArWpVq39VbclhspY0DGz/veqQeeQzeUAGxM0lqyc5Tl6TX+QTuUGukmvkBfy9paSJXylJvckWeO1EdSBHyD3yk2wnjWNPlK56ZAX5Am+kbsTWlVyGAzsfDnQxakE2wWtfJNPjZqs+WUZ2ksnkFRzZMZFnylEzUgGvOTJmARqRXXBQN8C+FKrW5CD5SlYjIyEqoxNkNOzMXricdiPjpSLUndwiF+BKiaofuUPekAmBLUuaEevgzW1Ghp+KmMpnG6oe0kZfksdkeO5eOZpK3sNlnx9eytwscps8JXNRXPbGwT7eJD0CW0xqzmNkWOSemn0PnMUDpHnEVqwakI1wCd6FS2pH7voWrpxulU8XpqZkH/kBZ1HfSJQMK2EHFNGoRpAnsBPFlE6oNuQsuU/6BrahufuapqEtS2opBesjmRLYYuoDn3uDQgO8YZWUIl8BT6tSNAQu9VOkZWDLD5jvZBU8bQuR1lRZPyT9A1ul1Atr4BSnHeqD4UXUP4pUsSNczy+AjwD9PIQ9plLbj6pSC+1pUkmr97RJbTZROsiPIiMCcIQ1fJTFk6RVxNaZTAvuhcpn6AOSS2kseUaek1GR+wrMQDIRycHXMNSE1wRdjITMq/cUUfXXdfivIo1H8LB5RybpZbhcVdqK/HqkN3kncgU+InRU5CWnZ8M9rkk4B/HsaSpquqrHFMSkylEWz8MB0uGe3+Sfay94ATleDIfgzSmCmoTKrKog7E85eIZ8g9/TVZuMBk1/TFtJl9w7UbUn5+DeVBulla6+u4Rcgtc7Dfv116ThpAyWc4ykSVmbSRYhoQRrQnJgBqrPAfXvcjI+uF9jagcPEJ2X1SFNR/1sdAwNNSFlT4e/frXS+qMcaQgthCdr0oDJ1G8uo5u+khHPSgAAAABJRU5ErkJggg==>

[image29]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACcAAAAXCAYAAACI2VaYAAAC7ElEQVR4Xu2VWahNURzGP/M8hGseMpPxgTIUylSG+0AJb+RFPIiuN1GGUohkeKBknh9kyJiQKUORMW+mDCGvHvi+++1199r7nNP1KuerX+3WWfvsb/2nBZT1n6gx6UDq5H+gmpPF5Ap5TI6SoZkdfm842UvukftkKWkab6I6k/XkFvxfm0nHzI5EdUlXMp9cI4dJy8wOoBFZTa6TQaQZWUeekBHptmqzt8lK0oSMJA/JRvjgUgU5RvYlzzJ6ipxFzmB9UkVekgvkBzmJQnOjyDOyCD6M1As2soo0gM1sJVfhD0r1yArygAyE311InpPRyR5pEnlBKlE8axgAG8ib0weWkQ9karTelpwnZ0gb0hNOoyLfItmjD80h78nsZH0/nMreyR5pCBygtfBBC1TKnCKyAzY3LlrXnhPkFZxOReIt2YNsjU0j38gG0oPcIHdIt2hPP7hEdFgdukClzOn5OHlHxkbrioKi9IlMRGpiF3ygoCnkCxyxYbAJNUKXaI+iqGgq/cpAgUqZa03OwebGROvq3gPwh2VgFvlJdiJrTvX0GT6IGuQ1uYm0LiUZUuPk012jvzEXRy42Nxm1mzuI1Fw+cmoumXuUPBcoNtcqWpdRreXNKa2H4FocT6aT72Q3sjUX0qpaVFqfotCcoiVjd0n3aL1GwZxmTmwuNMRHMiFa1x6ZViTUbaEhNIA1B4NmwKbVEPqwGiJvoj9sutaGyJsLs0qFr+gEtSOX4MHcCU6HClodHMpCo2Qe+QrPN62rFGREHRqkW+UN2Y50WGdUypykIawhuQTpENZQVSrWkIZwhLfBxR6iopmlIa1CH4x0CCvaKgVJB6iEzaluiw5hvayZpZuiIvebri8NSDWGakU3iwbzRWRbXxHQrbEAjngfchk+lN6R2sPlsAWuTQVC9ahGihux2uVM+GS/yO8EdZciqGgGyaBSpJGg1Om+LNZZfckmchqebXPhyMbSjVIF/88RshyeCmWVVdY/pz/iSqRRm3U03QAAAABJRU5ErkJggg==>

[image30]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAYCAYAAADtaU2/AAAB/ElEQVR4Xu3UP0hVYRjH8V9lZZL9ISujEMEoGsqGGirJFBKcdNEmExrEihpaQocwgooKcaqhwaHClhBp0UkoHUTEHLKhQRBJkCgqKhrEvo/POZz3duPizWzp/uAz3POee97n/SvlkssKZg8e4T0WMI8hHMV+PMOnqO07+lCGPFzGl6jtG7qwUVnEPnINP3AFa4K2AjzAVzRhVdC2Onp2H7uC50uOdXRJPiIrwAqJswU9UdsFeWdxduMeDgTPsoqNolk+qk6sD56fwGP5bLQpKWotzsv/F85Q1qmXr+VD+fRatqEaF+VreBvrorYjuIvt0e8/zmnM4SkK5SOrQAka8Vm+lhuwFTdRtfjPZeY4ZtAvH+lenJQXUIsP8im3Tlvk0x4vSRwrqh2z+IgRjGJavuN3JK8mOYS3eIF98s6sE0sl3uE5Tsl3eWnU9mtsM9qs3VJS2EG8UvrmXIyNcALjOIPyoM3Wc0pevXVap9RjFca+M4gGJe8cw6R8I6Z1bBfJsHxKryrZYBY7Lm/kl4utc6ZLogYvlRSej+vyI7kzfilMEQbklYWjtZTKR2udH05tSontByv6tfxY3kAHWpUsW1o2oVt+c9kZDVOMXpzVb6YqyGY8wR2lb7wVja2vLdc5ZS7wr8fWd0x+NP9J7Pza9Wmnwq7dTMctl/8kPwEcm1e2xpYNiwAAAABJRU5ErkJggg==>

[image31]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAYCAYAAADtaU2/AAAB40lEQVR4Xu3UzUtUURjH8SfNtyQwXxfmwsBA3VSgKEIiUkT5glqIqGCt+gtCCNyJIAUtUiNopSCCGLlJCxdCaYG4CNSFRYKgRIJv4EbEvs88d2DmMApzHVzE/ODDMPeZe+bc59xzROKJ5xxyATWYwT6OsYF5zOEHDvAN9Ui022KXyxjBJqqdWgHeYwttSAgvny2FWMBXXHVqmjL8kpPrvnMXf/EKqU5Nk41PWEelU/OdJDzHHjrF1t1NDj7jD2qdmu9kYhI/cdOpBVOCZayJtT0muYFVTIm11I124CF28QX53nWd8Fs8Fh8vnA6q7dWt1Ivk8HIglzCIQ/SILY1Gf3sH17zvUSUNr7GDZom8vlX4Lba3i5ya7+ge1QGXUOzUNLrN9HDRrXbLu6aTq8AAhpCLcgzjHZ6hDx/EOhLpYQKHhZ5UE8gIua5trMOi2IChe1d/14oWscGvo13scPmORqTjJbpx0W6z3BMb9EjsmNwWu0mPSf1cwajYMZni3ROM7nN9wXS9X4j9SRa6xCZ5RWz7jXvXon7xTot2QLv0CHliL2C/2GS0W7oU02JbTycWszwQe6IGPBGbyBiaxFr7FG/EtuF9ieFT38ZHsVbrC1gqNhE9aPRPOjAr1oVIZ0M8/2n+AfQjUXAS1L4kAAAAAElFTkSuQmCC>

[image32]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACQAAAAYCAYAAACSuF9OAAACIUlEQVR4Xu3VS4iNYRzH8R9yvxuS20IuxWxQQ0hyCQsipKjJrKZY2MxyaoQsTI0QUlLkXkITEdm5liiFBaIUyZRb2Uh8f/OfkznPzLuY03s2Or/6NJ3zvOd9n3n/z/N/pEoq+Y/TC0twBz/wBx/wAPfxDD/xEGvQJ35W/gzFGXzE4mRsEq6gDZvRu3i4PJmMx7iHicmYU4M3yh7PPSvwGQcwIBlzRuMW3mN+MpZ7+qIR31GrWFdpxuA2PmFZMpZ7RqEVrzE7GStkJl7gnaJ8Zc0svMJNRWnS+I1txDfcxYTi4R7F96rGImXsWF/gMnnL70W/4uH2DMJR/EKTosSlZqBinWbexxccxlesV/frZyHeKnrTtGSspxmHy8p+VnuP8YOeY0Yy5rgduGm6Jczp9L1v5t3m3nUS57AU49GAs4r1OBi7FSXfiqf612j9uUvZ3ATdmT3rEZ2+d+lW4wlOq2vv8cL2RFcqGuUWxeTcOL0LfT+/2amKtblc8U/4Ok+2SklWKR72W3FcfMEjxXHhvy9xXnFc9O/4TSH+vA+nMEzxoDrcUGyQdbioKI/f2nVMUfS3ZuxUxvopNd6JV7FD8coLD9qP4dilKJPX5zZFST05784L2KAopY+rXOKbHUK9YkJ+KycwHUNwpGNsJI5jj2K9uLzXMBdrMU85xgvaC9kTc+kWKErn9bRJcRgfxDFcwnaMRYuivXhC3R1RlVRSUv4Cv6dgSGjUCBgAAAAASUVORK5CYII=>

[image33]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFoAAAAYCAYAAAB6OOplAAAFTElEQVR4Xu2ZdahlVRTGPxsTu2McB7sTuzBQ7AD7jYkdmKh/DDpjOzaKothiB3ahiIWFiq0IBohgoqIi+v3eOnveufvs++a9+x7eUe4HH8w7a59z116990g99PB/x5LmReY6uaCHtpjfPMfcwpwukxXBC9eaB5szZLIeBsda5u3mmrkgB4Y93LzenCeT9TB1YL8jzVsVAdsW48ynzH1VDv+xCo99Y/5t/mi+ar5ovmZ+b35qHmPOXr3TTcxoHmK+bv6p0PlDhb7wI/NX8x5z9eqdkWIF82lzJ5VtqOkVSrFoTKuoBXjtRPMX86jq74Q5zEmVbKI5a03WTRAgb5gvK/pPAoZY33zbfNdcuybrFATYdYqonjuT9QMj3WBeZc6Wyepg3c3ml+ZGmQwsbD5pfqWyvBvYUpGFV6u5NwJsf/Nn8xo15cMFgXeswnGrZbJ+LGE+a56iSLl2WEYRHc8ojJpjZvN8RUrSUNlIN8HGT1KUufEq60PZ+MR83lw0k3UCJo/3zR1zASBt8EKf2tQWxfMdzO/Mi81ZWsX94NmF5h/m8er+5EL63q3oHUwFJTAlfKboM0tnsk6wovmmeZgKjt1aocxuam9oovUs8ydzH5XXMa3cr6jTfSqv+TexsiK6njAXyGQA/XY2f1Bk6UKt4o5A1tMPTlYh0LZXdOFtc0ENKPqY+bHad+lVzA8UNXrDTDZc0A/Qp1SihgKMuJciMM5VBEoOnp1t/qWBGp4yl4a22MDSIWNx8znFd2fKZP0bwkCDGZryQoo9bM6XyUCaXNLING+reNjYwHzcXCkXDBGUMUoc9XkPlbMLQ1KbKYf1kYwSspXK5XFqSIbmpNhw7sbme+auKiuEEWlulIQJKnhKAw2VaN5G5e8MFfzeeEVUdeowGhtGZF8lZ5HW7ImJg4mrOI51AErHK+bpKgwWayjmyQNUNhApxXzIoaQ0jM9lXqEY+/ZUa21ayrxMMRbeptgctXw/8xZFX8BxfeapCkVZ+635RfVvnJjA2s0Vza3RbGrYxPzavFfNky76b6Yog3eYi1TP2cfRiga6i8JQZMN95gXmaeYl1TvLVu/k4NDCIYnsbujHII/3+VDDCwo5BZ7JhA8l8CGc9JD5grmuWp3ABu40T1AYiA7/oLm3IjWpixieaOLof5zCSQsqNlNKeRo3TiAwls9kCXyD4zBl7Ey1ZmAyJkZGRi8A/A59Bb2YqTmQoT+Zhf6UA5ormYIj6GslbGq+pdCzAU40XCbdZM5Ze85GqMm/KY6wvyvmaI6wLynSko6O9/IUR3GO85STcdUzHIFDt1M46IHq2RiFs5Jy3Bw+othYDiKZozTGznsKNZEDw+cKfSGlDH0hkfaOIsP43TziuKPgt9nzeorvMYmcpwGHoTeHMt7PwfcOUlxN1ANyClhwhAZZ0AFQkm6PA4kaDE+5YPyjCRGt1GA2RxQkw1KmmBYoK0w6pH2eZTQpooz3RhOpFxFwBAcBiKHvUvQvMuVAxZ0PWZ43S/6mxNyo1oBtAYM2UXqomp7uBCiF8yYrjEc5uFIRtRiO9KXekcqUDOr37oqTFdFD12azpG5K7wQcMEGjc8CoI5UwygYk6Ji2yDYaKvu4VHHaJHJXjdemYKz5qAY/j/RvnigZSafPQROj3mFgmhoHnRSd1GvGQJro5dW/JykcQp1kPde2y1XrEwgCHHKGRv/iigjmPz2IYPoIWUlTTFfH/N5ExS0nPaAe0SmwGBry5tsAkcLGSfH65DAtgSBgQ/WbuGkBHOJo/KXaXQQb4L6i3d1AD03QZ8iEkZ4feujhP4J/AFr769kBjeaEAAAAAElFTkSuQmCC>

[image34]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAAXCAYAAAAGAx/kAAAA/0lEQVR4Xu3SP0tCURjH8ac/RlBDYUPQoBD0BlLQ0aFJWwMHIWyxFxC9iKCG3IJmBycRGo2gBtFZHBwj2nQoqSW/x+fGPRe8dtMhiPuDz3Cfc+7hnOcckTB/lgQa+MCXo4001nFj1YeoY3f8p08yeEETcauewiNOsWbVfbOBCt5QxCJ2UEbO+Q6UBRxhgDvs4xpZ+cUi3zE7eBDtV0t04SXPjIBZxjk+URU97kzZwq3oQj0kvcM/ZxMXOEYEB3jFE2LutOnZxiXyokcziaKGd5QkQJ/2RHthdrNq1c0tnYg+hXvRS5iYAjrivthnHIo+gRWcoW+Nd3ElczQ/zL/LCD91Lg6jN/6dAAAAAElFTkSuQmCC>

[image35]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABoAAAAYCAYAAADkgu3FAAABpElEQVR4Xu3UyStFYRgG8MdMmS1QxMaSDCVhIUMybQ1/gJWFnWlhIcpGFpStsqVsZU4ZN6zESqGIUHYknsd7T333uJtrWKj71C857xm+837vuUAkkYRIFDXQGj3SO13THu3SAd3QJjVTjF32/STTAl1Rra9WR5d0ThXBpfBTQIewlef4atm0Dnvjdl8t7DTSLU1TonNcre2gO1g7C51a2ImlYdiKu2E3VzKoH7ZnO1Tl1L4V3XCZXmiL5mgycExvOUFp3sk/SQmd0SKlO8ejqQvWtnnKdGrlsEl9pVPYhOoemtJW2LVBUSt66IlGYG104w2CHtbkq2nv9qk08H88jdM25XsneUmgKbqnFl9NyYOtVvvX5hzXggZgXcgKHEuiGVrB18n9XPEqnVCRr6aPs5eeYW+V69RSYO3UG+hNlDLaoE6EaF0N7CPVx6qLvaTSIKylGutKBE+cFqW2LcGGZYxGqRq+h9TTEb3BfnYeYBeqTfp7ARvpPoSeOLVRG6+h+LNof4Zge+G289ejFqvVs7AB+JMUwx6iATmGfWdxQWdE8q/yARh5UTnsDZrdAAAAAElFTkSuQmCC>

[image36]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmwAAAAjCAYAAAApBFa1AAADpklEQVR4Xu3cW6htUxgH8M/9Fk65hoTEiUTKLbeTJJQXlzh5UAp58ESJFOWaBxRSknhwKUmSJOoktyTl/uTRJSW3QpH4PmMse65p79067bXOSf1+9W+tOcY4a8/O09c3xpwRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPzX9ZlvM59nPsu8l7krs+NwEQAAW8/GzA7RirR1mW0yZ0ytAABgq9qzf76Q2b5/361/AgD8b1UXalPm58wfmVf7+MGZtzJ/ZT7p6+bl0mi/W3k+c1DmnX79Q7TC65TMb33sqcw5sXQ/3/c1u2f+jLYNenU0dZ9v9++zqI7chvHgCp7NfJn5Mdr9vpv5NHPNcBEAwKIcF60YOa1fb4hWKC3KkZkPMydHK7IezRwztSLi8WjF0UT9m69jepvz7sH3slfmjtHYaup827njwRVUt+6JzEmDsfuiFY2Tjh4AwMJUMfJ75sZ+/XTm9KXpudspc2fm3syZmaOnp/9xf+aXaAVdFVaXROuund/n65zaqf17qU7Xk9E6ggcOxldTv3veeHAFh2U+yOw/GKui86vBNQDAQtU23zeZh2O+W6ArqW3N2oa9ZTzR1VOftS1a3auzMntnfs1cFa3bVt2ttdqcgu3WaN206vxV6v/q0KkVAAALdnu0guTi8cSCVFetzqS9Np7oqjCrAq26cbW2Crcq4G7I3JO5aGnpzLaN9puTM3TjfJE5/t/V016O1r2bqHV1jm19v67OW3UEq/D9KHNdZuc+BwAwFw9GO/Q/S3etzp6Ni51h6hUbq/3OY9G2XKuLVluxyz3NWWfLvstc2K/r96ogqgcVxufddonW8ar7fz/zQGbfqRXLm7XDVn/7p8xNg7Fdo3UIbx6Mvdk/qzCsBxJOGMwBAKxZncV6bjw4Z1XIvNE/SxVaVSg+1L8PHRut47XPYKyeCH1pcD20Kdo5t1Ivz71iMLeSWQu2OhNX59fqHFup7l7d22Wx9MDBHtEKtupU3hatMwgAMBcXZF6P1hmr13ucPT09N/X0ZnXB6u8c1cfqLFh12CpVENVrNiaOyLwS05262j49cXA9VMVSFXm1DflMZr/p6WXNUrC9GG0rtlL3WFueH0d7aGKo7vfy0RgAAF09wFBPnG5uV6uKwXoVyFptF+1s3QHjCQAAmsMzV8bSVuuWVg9B1Jby5LUoAAAMXBvtqcxHModMTwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMAW8zf7gJYUGw1HnQAAAABJRU5ErkJggg==>

[image37]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAYCAYAAACbU/80AAACGUlEQVR4Xu3VS6iNURjG8cf9kruj3NLJnQESA5c4lCRHDMToUAYKUZRkgIHSKRIRAwMDRAqJwkyidJCkGBiYSJHkEjIQ/9fzrc76dLay2WWwn/oN9re+y7q8a22pnnr+g4zEKbzBd3zDbczEBFzA+6LtCy5jDLpiCz4WbZ9xCH1UReJlu/EV29Ala+uN4/iEFnTK2joX145hWHb9jxMf3CyPMDoSHUoZgLNF20b5oykjcACTsmtVJUa1Vh7lQfTIrs/BaXl2dqq9c92wQX4un7Gqs0Je6xPytEcGYyE2yWvciu5F2wzsx5Di919nEV7jHPrKI52LUViFD/Ja98JA7MOCn0/+o8zGC1yXRz4W8+SOLMFbeSni4+vl5UhLlRIztwev8A7nMVF+5oy8W9owLT2QZwqe4RbGyx+NByPz8RJX0CTvisai7dcMwkW5OFMHh2MxxqlcxKXEiB/hIVZjatYW6/0c9+SPL1d5O+aJEd+Vi7MnVmIr+uU3dZQ4kO7IU71D7YUYiW32VD6kog4qHTbRqWW4L8/gYexV+V0V04AbeKLy6CON8uijEx2uX5HYmrvkdxzBTfmU7Z/dUzExRSflkzBelGcoLmGNfrOGcs3EfVHIo9EsL2tTdk9NE0sVVb5O7mh0/Jp8uEU91DxL5SKeVfyOLbwdDzA53VSLRJHFf8lj+d/xqHyAxb/mVXn/R31NTw/UU0/KD0WJXi5GznyeAAAAAElFTkSuQmCC>

[image38]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFoAAAAYCAYAAAB6OOplAAAEn0lEQVR4Xu2ZZ6hcRRTH/3ZjI5ZILNFHEmzE2AuoCIGoKCaaWMD6sESsUbEriliT2LChRCOJGlEUe8FKRGyYKMGGop/Mh3xRFFRURP+/Pffm7c7OrvG+zbLK/uHHe+/OvXPPnXPmzJl5Ul99/d+1jbnV7JU29NVSm5mbzCSzWtKWFQ/MNaeZNZK2vtprD/OY2T1tSMXAnmnmmY2Ttr7+WYzf2eZRRcC21HjzujlB+fAfq/DYcvOX+dF8aN41H5kfzDfmPLN+8Uw31Et27WjeMFOVH0Otbk5X3DTQ2NQgvHaR+dmcU/xdagNzY9F2gxlR17aq1St24cgHFFE9MmmrCWMeMvea9ZK2enHfw+Y7s3/Shkab18wy5dtXlXrFLhw803xqdknaahpj3jKXmjWTtnqNM0vMmwrjU61tZptfFAsqM6Ub6iW7qDy+MFPSBrSnwguDapFbFNcPN9+b28w6jc01ce0W87u5QN2pXHrNrp3Mx+YMZRx6kGLBmK7WA01UXGd+Mscrfx/VyjOKfDio/D2dVq/Zxex631yijEMPM1+ZQ9KGOo0yr5ivza5JW6mdzZeKXLhfcY2BICXNUvv8X1VV7aqqLRTj1OpbtjaLzPVmraSt9iCGtBto0su35kWzadKGysqFPPiU2aS4TvSwy9y7+L3TqmpXFdEXOZ6qolU/5UCzUyTIGnSA+dxMU34wyhcw9a5VxlMaWlCJmoOV76fT6rZdlIYcT1yt/LsQqeMDc6UyhcVuZqk5WXlDmCbUhxT/uWJ8I3O3orw6RkO5aUCRPx9XlDvUmReb58xVCoMpK29Xc91JZLDIpdfrVdUutK25U1EWLlQ4jFx+onlEsV4xmIPmMnOgYp+BUz9TpIbcBohNy2LFLGpaDDlIettcrowXFO0keCoTOipFRzjpefOOGtMDRvLxlDsMLD/JlSxY1Ot8IFvVfc0LZrt4rKYNFR/7hyIyWkVPFbsQefYJc6Gib84nsPE4M9ncpxh4nMyRxPkKJ3EfKWqiWguHfKIoMJqEZzhMWqD4yFI7KDr+VbG9/U1Rr7K9fU+Rbl5VeC/NWRhGTXu0eVLxcbyHqcVHHqkYED7u6eLeUusqFs8/FdFWbxMajl0MOMcMpJPxxTUcQaAdqnDQs8W1AYWzGDSeO0kRAGmfpfieUxVHAPWOXyFuOEttbqgopjZpgTRBKiB6WBhfMhM0lPNILyxk6Wwi3RDR7Pw6JRaomxWBRb8MIOmC8m8rRWCw2DHbiM7SVqKbrfw1ioAhzaSpinp9jpmv5uBYIQptomGGMrmlorZXTEnyHRsFBpNoIm0QFSxUVALHKk6+No/HauIjjjCnKFOPDkP0RVARAAQC77xHEbU4+lxzhyK/kzKYUUcpSmDsxv59FDMytWuseVnt9yO1l5Cz2pUu/1YsOKSJBxVnDEQT0X2FIrpJJ5y84QxKy3rjGAB2esyATgsH368YYAaPdaOcTeRhnM8ielfxO5G8pSIYWF8oGkYV95cqHcjiTLS3FQ/zAqZS6q1uigFn8Zym5nTSq2KzRFCR21dKrOScC/Afg75WTuRz1prh1ul99fUf0d9DeuvuEgSoYAAAAABJRU5ErkJggg==>

[image39]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmwAAAAjCAYAAAApBFa1AAADgklEQVR4Xu3cWaitYxgH8Mc8HBmOC9OJkyHDIRJSyHAncsmNuEIo4oLIcEW5kaEoFygzSe7ImERIyFSSJEO5MXU6ReJ5et9lfXudtbe1d2vJxe9X/9rv+317fd9eV0/P+747AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAf3V25tfMX5kXM4f1+Tf73MeZc/vcPGyb+TTaZ/+R2ZA5qI8rd/e5R/r4z8yJmWczv2S2ZJ7PbJ+5qt9zV2a3WL0dMpdOTi7j0My30Z73TubtzNeZyzK7jG8DAFiM4zJfZE7t420yj2WO/ueO+fswWsFTzzopc8ySqxHbRSvObunjPTNPZK6IVvSVAzJH9p/XYsfMdZOTK3g42juP7BStoLxpMAcAsBDrMg9mro/WuTo2c1q0YmpRbotW7JyeeWDiWqlnb87c2cenZB7N3BDtHas7dnm0wm6tVluwvZ95ZTCuYvG7zFmDOQCAhallyB8yF8d/U4DskXk8Wneqiq9pfsw8Ga1AOzBzfua+aEuQt2fOHN+6Jqsp2Oodq8D8KHNHtO/qqSV3AAAsWBUvVZB8FeMlx0XalHkj81Jmn4lrI7Vn7IVo+8eqaKv9dtVl2ytap62WJMuumVszP2ee7tdrr9m7/frQJTHeLzctx49vXWLvaPv5jujjum843j/avrt65/WZw6N9n7WMCwAwF9W1+ilz3uSFKU7OfBNbFzuj1CGGlZZTq5ipJdfqWv0e05dES3WzPoi2RFtOyLyXuT+2/vwqnKo7uHPmmolry5m1w1bPujDGy7GlisR67xv7XN1T310dkLg6c0G/DwBgbqqAeibaUuWiVOeullsvGszdG63Im3bSsk6tfjYYb8x8Hu2QxFAVfjdH+6zXY/a/YdaCrQ431KnZg/u4fu/LaEXrqICrQxH1/d0T472AAABzUZ2hl6MthVZn7NU+N2/Vkap9X8Olylo6rA5bzdWG/iv7/MhDmWsH432jFXuTS7a1BPpctIKq/gXJGUuuLm+Wgu2QaKdVR+/4VrQTtXVoovbVjRwVrSNYS6evRftXJQAAdOdEWzot1dmqwmoWVZhunJxco1oarf14pfayVbcNAIBonbva/P9btI5XdcRWOjywCPtlvo924GD3zCfRunJ1EAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPif+BudSpDmdd6shwAAAABJRU5ErkJggg==>

[image40]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmwAAAAjCAYAAAApBFa1AAAC50lEQVR4Xu3dS6iVVRQH8NVTB2UvjV5UYBRFGUFFD2gQBNZEKtRGNcqBEA0KIqdROoheoMOCngORBhERgREFBZERJA1sEGINQqKQigZha7m+4/mOOIp7vXrv7wd/uPvb+97zDTdr7X1uBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABz677M/syezN+ZL4fxReNFAAAsnMcz52ceyXw+PFuTOfPoCgAAFtSqzGmZ5zPvDs/OmU4DAJza7oxuIx7OvJO5PPNF5p/Mb5nzMudm/h3WbOpfmzdXZA5Gf1a9x22ZXZk/ot9zdXTl7NCw5pX+tSOqFbpuNAYAWDRez/w+Gl+X+TZzz+jZ1syFo/F8eiJ6czZpaVa7873M5qMrIl7MXD8an515P5xbAwAWqZczf0a3Fcv6zGeZB4ZxbZjuHn4+ER6Lfp9lw7g+++3Ms8P4rGHNGcP4wehK28+Z7cMzAIBF5amYVrTq7NfK6IpaHeavattL06UnRN36/DW6FVvvdGVmQ2ZH5oLMC9OlAABLQ23M/oquaN0RvUmqatbTmW2Zh6dL47LotQeiW6S1oavzbdWynCt3Rf/9am9eE/0+90dX2eoM3aTSBgCwZKyNPuj/UPSlg2qNPhp92P+m0bpSc99EXwZ4MrNxdnrG6dGbu7occLzsmy6dUZu076L/9s3Ds1szX0dfKpi0bkt9xt7oSxJfZX7K3DiaBwBYFGpT9GP012NM3Jv5YDSeqPNs9V1nr2Weifn5rrNqyX4c081auTrzw2g89mbmueHnS6NbuMun0wAAp75rMx/FbOXq9iHHuiH6kkK1Kz/NXDU7PSdWZN6IvlwwcUl01e94dkdX46raVmfdbpmdBgBYWrZEn2Mrb2V2juYWQlX4qhJ48bETAABLUbUbf4m+jFBVsO+jb5dONnALod7j1dACBQA4KdX3sH2S+TD6PzYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA//UfmtxiUtiI3sUAAAAASUVORK5CYII=>

[image41]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAYCAYAAADpnJ2CAAAB1ElEQVR4Xu3UP0iVURjH8Z9mlv3REkIDIYcaXAQR/0QOoYaKNVRCtbS51OAiiKJugks0OARNgaINEjoJVigIlklRtGiLggWpUYG4CFLfx+deOr4mwr13kvuDDxfOc+/7nvOcc66UTjpJJAN1eIVf+INveINZzOE7ptCAI/6z5HMKg/iKmkjtKlbwBeW7S4nnAt7JV1IYqRXgtbwD1yO1hFOPVTzG8WDcWn4D6/I2Fwe1hJOFTvkK7spfYjmLNvmezqA6qCUVe/AYtjCNJ+iPjdmq+5AX/3IqUopFjOJMMJ6JO/J2PkN+UKuQT24bn/EAx9Asn+QmerV7e3ZiLbqH3+iStzdM/MDYS68F4/a72/igfyc3G1XyU22n/r+xWT3CDzRFapYi+X20/bXZx3MU3ZiQn+pi+You64B9thW8xCdcitTskrdiQ77K80HNWv9cfqpvYRyVQX3fXJFfdrv0p4PxXHTIW23XwR4WzrwE7/ECT7GAxqC+J7WYl2+6/Z39xFt5++xzWX4VHmrvCbUX38SSvAPnMCx/8cngeymL7Z/t16S8zXaa7+Oj/PSmPLbiEQwgJzZ2Ud6ZHvmEUpYyDMkPkl2JFpyQt3ZNfgfbY2PpHKL8BZNmV61GGcIwAAAAAElFTkSuQmCC>

[image42]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEUAAAAYCAYAAACsnTAAAAAEKElEQVR4Xu2WaahVVRiG39LmwcoKSypSg4osIo3606ANJuRQNpNoktBAPxqkQWgii7SZsmwAabAyCgXNMCkqKMiMQjIKKxqUIhopqZB6H7+9OGuvs4/eX4GwX3i45+5v7zV801pSq1atWrX637SNOc28bn4w/5oVZlD2zmDzsvmnsv9o7jA7Z+/sba40y823Zq1Zbe5RjDXZXGW2q95P875p/lSM+7dZac42Q82z5rvKBp+ZWWZfc5v5MrN9bi5QrOP+7LuN5n0zSjHnaPN1ZltqDlIP7WVeNBvMz+YsxSBJ/c0M84gZUDy/SDERC7vM7FfZcMDF5gOFwyepPiZiLOZdb06qm7StYjychhOSQ5PONL+Yp82u2XO+m67Yy71mh8yGjjXPmaOL5106UjH4bMVgL5k9M/tOiuwgimlj25urzR9mviKCpXY3z5hPzOGFDR1iPjJvmf0L226KNRGk8ep26MkKZ76ieqBw3vWKzHtC9Yzm941mrLrHqwnjueZOc5RZpYjsqdk7lNCj5ojqf74Zp3iP0mpyCGKBt5gFZo+6adMYRPsnNUf0UEUJ4jScV2qkooQo/Xz+IeZuRRaRhQQGpZKdqXpmNYrF3GqmmB3NTYr+8bA6Xj7BPKhO9lCHb5vvVXdeqX6K8qLe+Z0LhzHvr+Z81SPHb0qYjdFbyJpSh5k15l1zQPWMvZBBZMI3ZpkZWNkoa3ocVbFF0QjnmRHV/3xEutPYqDs2c7m5RrERavZSRa0vVHcG9FX7mNfUaZZNUALXqduhiIygX5FJw6pnZDLZzh7ocQSOLGfd7GGaog9uUccpSoNFIrJljiJbSDU8TXqfXtlJxxcq+w3q4yQNSun/quLUyMVaiDLleUphS6IHsWk2P1xxWIxRZHfqVbQCHEb2PKTOHjcron6JYnM0ziQcxYI/NhPMU4rIIAbm6CXty1Oq1DGKTTFPrjQvTZpels+N+O4LxRF9cGFLIlg4jjKhvNl4WiPl9J751JyoOKb52yftomhKZXfnOSXFWU40HlCnOfGXU+F3Rb/o5RTKihpuijSnGcf7b4omn4+RHEZ5EgzW0iT6zPOKbKKcR6mTtTRe7lvcmeiF16q7kfcUUXhS0elLsRka6V+Ki1eqaxY9ReEUUjI/8pJoyHeZm9W8Ker8HUWjTCdaEg6bq5j3CjX3E8S8jyn6zuPq3I8QAVmk6EtvaDMXtFJMdqGiWeY32CQGJhLrFOmZi75CSnKccqnLHUN94+ip6h2d0QqHL1HndEiiV3BvoSyOL2y5KLl09J6jeraRzfMr23mFrafOUNwBUpf/SnFnKI/FiYrLEZEtRUensS1WjEWfuU+RVUOz95IYj3sCzS/Ny8WMSFK+ByruM5RNOnk+NLerOdvSLZsyzy9vKB0WOI3Ma9WqVatWrVptHfoPRt7bRE9rjl0AAAAASUVORK5CYII=>

[image43]: <data:image/png;base64,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>

[image44]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEgAAAAYCAYAAABZY7uwAAAEM0lEQVR4Xu2Xd8hWZRjGr/ZWs12UpC1IKxuktihaKloZRASiNGhQIe0y4tPUJkXRQioiCdpGKAVZkP0R0aKlDRo0aVAZmKRIXr/3fk/ffc57jtif4rngx/d95znjee79Sa1atWrVar3QRuZks8j8Yv41r5pd0z17mOfNqu76b2a22Trds7951vzavQe+MNebnc2tZmla+8k8YfY2k837ZnV3jff3mUHmUvNJeu5rc5HZzAw1b6S1j81xqtd+5mbzlvnRfKb45sVmJzPdjFfYo1aDzdNmhfnDTFL55k3NNeYBMzBdz+KeG8zfioNtUl7WMeYH86Lie1kHKAzxjsJoWUcpnsNxGDtrN/OYOUO930PbmRnmL/O6Oc0M6K5xjj6FI5eYEd3rtTrIzDN3KIxENGyf1rdSRM2ZarYyH37SfGdGV9bY/BXmH3OTIgKyhii8y0YxViG+NU4RmW+aPdMa7zzHXGY2T9cLsf9HzXKFc7csL3e0j3nXvKDyeUtiE2eZW8zB5j1Fup2U7iHNHjLD07WqONhH5hX1epp0ec78rjhwVbuY18xX5rB0neemKbz8odk3rZE2d5q90rVCGIxoxjgzVW8chFEIBlKs6rT/tIUiDKcqXsTN1Jv71V9njjX3qtnKGJm0/FNRb3hn1oGKGkTeD6usIQxB6lEf+Bba2BxhjlbUGoxEpCMimvp2uuojmnd8q0jZuu8V2sZcrd6IL4mCPNcc3v2bTRDqn5uRilC+xFypZitjkNvVXzCboDBTF6riGilOgT61e213xUHZ30vmezNG/Y2FyCjqSRZOpVbiZKKoac/rrFGK9KGaI6KI0OUDN5odzF3mlO56nUgRiihGJU2zMN5tZqWiDtUVUyKCQ1FMSXf2gBEwDkZ4SlGHSHu6Fw49pPNkr6grHyjSeWxl7X+LMD5XEa650GE0Wip5TxhT7NhYk7ifkMbTO1bWqEfUpZ/NCZW1QniZGkgHvEBx+CMV0UJEPGyWmbPNdeZ8RdesE1H/pflUkdpN4nnq4Vq7FzlIatD+ci5zHS8xm5D/95ht03oWRuZQHG6OejsKB8V4dKm6gorY7LWKDkrqTFT/94hAIpj3E+n8XnVCFmMCtQcjYawmUeR539pqVOdlj6jcWgudqPA6rfly1acGwsMPKjxcHQOy8YiCPFxmcd+FCgORqoemNYzXp6hhdLmmYbAQ6Xm3ooMRaXX7Jg0fV4wJdesdFXPEMypPzoXoLMw1ubPUqfAY02m1/lBb7lMY6DyFIeqEUUkfjDxL5S7IPmn1GI9ZrNoh68SeXlYYlOwojMBP0oqGcLya99MpXozmRXf5xkxQ2fv8zoQ6XzEHVUWILlBEGO/gAG+bqxSFnYNW//XAa3nYy2LjC1WedRCHmKqYo5ic11V0RqJ3saKWcg6axRT1TvKtWrVq1apVqw1DawB6VttRr2SYNAAAAABJRU5ErkJggg==>

[image45]: <data:image/png;base64,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>

[image46]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAXCAYAAADUUxW8AAABL0lEQVR4XuXSPyhGURjH8Z+/r/yPJAObktUgiwyUxfSOSpGyyGCwi4FNNotBWVgZKJn8GyxKMZASFgPKzPfx3Pt276H3Zn5/9VnOc+655znnSKWddszjDB/4CrzjCKOoiL5RJcblH61gDje4wxQmsYgT+SJvmFC0wDDuMRsNdONK/hfbTZx6rMkX2EeLDa5iE63RpAE8YhsN0VicIbzgEG3pklSGvLy/ZVSlyxqUL7yE6qD2s+0F+cfWly0Wpw7ruERvYrwQ62sLD+hPjNuhzuAaY0ovWkgnTnGMDjTK+9zAufxwy+PJYaynZ1zIr+YTe/KrbErM+xXr1x7JK6bRg9rUjCJpxo58e11BLTN9uJXfey6oFY2dpl3RE0aCWmbsGR5gV3+8nKzU6J8HVKr5BoRtNlxe5fiYAAAAAElFTkSuQmCC>

[image47]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmwAAAAjCAYAAAApBFa1AAAErElEQVR4Xu3ceahmcxzH8a917DtZQszIMnYRCQ2hLKNZpNHkD6GQ+EOypUxKhMRfdkOy/2EUjX1LKUsSWVOy/EFSQkh8PvM9Z57f+d3z3Lkz9z7jj/t+1af7nN8593mee//69Pv9zokAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBa2k25tR6cpNnKrHoQAAAAa+Ye5bx6cJLWjXzfHesTAAAAfY5SXlL+Vf5QdlHeUv5UflZuUzZX/mmuuUBZb8Vvjo5ntZYplyh/KWcqlyo/Rn6HnQeXjpRnwRYr6yibKksiP/8LZZFyu/Jd5P/m+Oa6b5prnlN2j+FOV16pBwEAAIZxGflFmdsc7618oBy78oqIG5VtiuNROUx5LbL8bBxZ0lr+nvcpZxdjo7KZ8oCySTX+g7Jl83oD5Url3sHpuFo5pTgepn3/7eoTAAAAfWYov0XOJplntF6PQfHYSjm6eb02uSB+Vhy7PHkp8YBibFR2VV5V1q/Gv1Z2aF7vqdysPNEcu2ReG1nGVsWzlJcp+9QnAAAA+rg8eDnUs0UuG5718Yza+ZH7rbws+n84QbmjOF6uLC2OR+kk5avIElZ6LwY3DBykHKi8GTnbdlGMLXjjObkJAADAKrmU/R5Z0o6MLB1XKZcrWysLBpeu2D/2sPJtZJHz8qn3cD1aXDMV/J0uVM5VZkbunfOesW2VPSKXbJ+NsYXqYuUZ5Zpq3O+3r7JhNe5Zu8eU+6Nbtk5VPi+OWy5nnuHz7J9/dy/lfWWOcmdxnR2q/K28HTlT6BlLf4/WMcrCGPs3AAAA9PpJeTzypgMXiHOUp5W7y4uac97rdnjkXq6zuqc72iLoTfh98eb9Q1Ze3eVS9q5yRHRLjnkJ0vvbjotu4fFPL+X6BoBPmrGWy9j1kfvgSi6dXhL2uEueZ8rMZcrvUZcplzvPPPozzMujLq8ut36fkj/zqea1v69nCMs7Qz2Ld1pxDAAAMK4vI+/MbLmQeAZr+2LMvJ/tycilyo9i9ZYAV8ctyqf1YMFl8aHmZ8l7z16MwQ0UrWGFzYXKJW2jyFm2dv+Z71R9I8b+fd6z5j1+bZHz9b5hoy525tk3l94lynXRLZ5+7SVUzx4CAABMyPPR3U/lmS2ntp/yYeTSpJdNx3t0xWR4r5iXXofxcmm9BNnysq5/vyxIbWGrbwh4MHKZ1DNgLqH+aS52vsHBjzQpXRHdkuii5xLXx8uqXhbt48/x9/eSMwAAwJTyYys8g2VbRM62jYKLYN+slXmj/zzlxMhy5tJ0cGQZ87Kul2s/jixd3jfm96kLm58/55sa5kfOInopuL4BwOXUe+fqJdmJcNFz4WwLYM2f3f4fAQAApsxOyveRe7Zc1uZE3l26th5k23JJbPfBzY5cvlwaWcZuinwumh+62y5retyzgd4Td0NkEbtLeac597LyQuTfVHLJeyTW7PlzLmu/xvA9fp5d82wdAADAtODHkrg81jNyHj+jZ9z8gN6JPIDXpc/76abS/sHz1wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgOvgPfjecZ/KyEgwAAAAASUVORK5CYII=>

[image48]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADUAAAAXCAYAAACrggdNAAADG0lEQVR4Xu2XWahNURzGP/M8T1EoJXPmubgZIsUllJDhUjKkSF6UMhVlSoZ4IHOmQjwgmTIlJVE8GEp4kVCe+b6+ve9dZ5+zzznFrfNwv/p123v9z17rv9Z/WBeoUY1qVF3qQNaSx+QX+ZPgJ7lNJpM60W9KVnXJPNiZ7WQ1eUPekQqymGwiD2HnfpAFKHHHJpD3ZBW80O7kJXwqOr1YTcle2LHrpHUwVnLaQY6SNtHzSPKJnCbNYqNIZeQruUnaZQ6VrmqRmXD+bCX1MocxBnZ4C6mfGCtZKfzWw04pb+RkrCZkH3lOegfvS17KmxPkIxkevFcxWUZek6nIdLbk1Zk8IndIR9IczqPD5AlcVGrDTo0m58grcij6bS4NIAfJSXIRztm0TdF8k0i35ECg/uR4hKp12ryVUs58IU/hEv6bXINLfovArgs5QAaR9uQsOZawkVQhdfIr4EJ0CrZTRIRqQBaRS3A7GZcxWiV9Q0VtFhw9SpGdyP5epZRPar7fyFLSkzTOsKhSH/hEF8LFZCXcBvqGRlQrcoZshB2UQ+eR7Xws5epdpDullFAUDY2ey8gt0is2SKolPKHCTCdRrOTUZvKAdE2MheoBt4I5cAjnUiGnpsDrUwhKo+DNVSrk1GDyFu5bCodipWZ9n6xBdguQFCbl5AIcsmFDT6qQU9PJM9Iveh4Bp0pOe02sUv6ZTEyM5ZNOdxdZh/RQjdWI7CGX4SKUS4Wc0tp0MuFJKff1N0vavRvwbhZ7U9CpqIDMJQ3hieJbSSxVJt0lB8Ibp9PUnTLnImCn7iHdKX1H1zdVUEl2yimFdpa0qHyFISnlhPrVNvjWrljfADuhcJwBl+ex5AV8S9G3d8OhqpxtG70PS3Ls1PjgXWgXF5vZ8CZVkCPwXP8sTa5qF/5rchVewHLyAV6YNmsJHKK6DO8nw+A+JYd1ajo92U2Dy/V3OGLmR+9DO1VonZKiSpfqK3CRSOt7/02aWIVBTbeQVJp1ymnVMFaxdtWmTvCVSj0qnxSOCh+Faz4Va1etUq9SMywUEnJ6CJwb+VSsXaX+AtsYiFuS/ZobAAAAAElFTkSuQmCC>

[image49]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAAYCAYAAAD3Va0xAAABKklEQVR4Xu3SvStGYRzG8ctrQsmgpBSFidEfYKDQw6aMkk3Z7DblDzCYbFIGmWRgsYjBZDRJMngplIXvr+t+dI6ejmeznKs+PZ37Puf33C8/qcy/pAFTOMM7vvCJC1TSfBu20lx4TM8dqpEu7MsvReFsmjCPg/Tbkp/OZxjXuMJgZjz+YA1L8soKE8uPbTxhF51pfAibmEVzGitMLHUDH1hFq/zxtlys7vTgGHeYlou+4gZjmff+zDhu8SBvbUZeTdzeuurcViOW5as/wYh8ZhO4xzn6f94uSDt25K0sykUicVt7eMOK3AKFiau+lM9jNDMeBRfwjFP0ZeZqZlJuwkN0/5rrlYu8yEWrq81lTm7AattHD8VH0blxbnHtR/KBx3xsPTp/QGXKON+I1Dh+MpYqsQAAAABJRU5ErkJggg==>

[image50]: <data:image/png;base64,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>

[image51]: <data:image/png;base64,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>

[image52]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmwAAAAjCAYAAAApBFa1AAAEbElEQVR4Xu3dWchVVRjG8TctNWkyo1HyawAthIKKRqSIgkiJxIoiFMEmsaKiqGggom6KCAWjbormhIocqOiir4HmqKCB8KIuoouIRkoKwp6Hd2/POvvsQs/wXej/Bw+etfb+PPusq5d37X1OBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAO42TlYObkwPYRTlX2ad5AAAAAP15vjkxBLsrt1X/AgAADOQJZYvyj3KCMkf5VdmsvKTsqlxTnfOnskf+2cjsqbyp3Kz8rLyuXKFsiryGEzunDsXZynHV61nKj5Hv83bkeriY89jrcUTkevweuRYP5p/9p1uVp5qTAAAA22tyZDFyRzH3jLJCmVSND1GO6hweqReUKZHv/ZtyYzXv61yp3KdMreYGdZjyRnQ+p10duR4uzMzbmh57PWr3F6//z5jyTuTnAQAA6Jvvt/pDeaAYP6ncElm07KZcFVkwTSS/rzt9i6uxiyoXTR77GodhvvJpY25p5HrUReGpyl+R62G+Lp+zLdyNfCy4lw0AAAzBD8qzkQXaacqFyprI+6/uVc7onDph3P0aVw6qxqsitymHyd27zxtzZ0Wuh7dmvR6HRnb6vB4zItdjW7nIvSlyKxUAAGAg3ymvKEdGdp3OieyyuUBxZ6ncgrxT+UVZWx33PVofFMeHxdfhIm26cr6yLvL+ur0jr+ld5YKtZ3e4wPN1lVw4PRfZ7XIhVvM9Zh8WYzslcj1mRq6Hi7afItfj8uh02sxdvy8iO3DvKd8q8xrH3Z0s5wAAAPrymfKJckw1Pj6ykHkoercf50ZuCU5TrlP26j7c5aTIG/bb4q7VxZ1Tu3gr0Q9D+IGAwxvHfK/dxsjO11uRW5SlRcrsYuyiaZlyQGTh5sKrdmX0bom6SPN6XBSd9fgmcj3Oi971eFy5u3rtYrHeWja/n7t4LjQBAAAG8qryZTEeU75Sji3marcrqyO3K93tGoVLle+jtzgquRDyE6RNzYLNHTJ3Bd0xc/FW/s3p0bslul/ketTFmrlY83q0+Vp5RLkr8snWkruDD0d3Vw8AAKAvjyrXF+MDlSXR/fRk7cXIrteCyIJnFLzN+lFzslA/GNFWULpgGyvG7nLdEFmI+fO8XBxzl268OqfmjqHXo+zc+TN7PZpcDK5X9m8eqPjLeF+L3i4gAADASHnr1FysfKwcXRwbFm8h+v9v4+LoHuXMyO9n81dm+HVdFLlg8wMLLsL8Cwae9z1kLu7c8XLxVnPh521OPwnaDz9MsDzaC1u7Vnm6OQkAADAqLnb8HWX+0lh3plys+F40bx9OJP96wN+R7+2v/fD9bu9HFmmXKRsin+j0NqS3Iz3v4m88srtWbpeat3W9zbu9/GCGu2e+n86FYRt35vwTVQAAADu9S6J929G/YNA23+SCy9vAw+LO3UJl3+YBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMAO7V9gjZngAsq3MAAAAABJRU5ErkJggg==>